{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DK_zgOn0ryT"
   },
   "source": [
    "# **Lab 2 Basim Sherief 1210207**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czaY5SFEp3Ec"
   },
   "source": [
    "### **Requirement 2**\n",
    "\n",
    "1) Complete the provided matrix addition example, following these cases:\n",
    "        \n",
    "        A.   kernel1: each thread produces one output matrix element\n",
    "        B.   kernel2: each thread produces one output matrix row\n",
    "        C.   kernel3: each thread produces one output matrix column\n",
    "  Analyze the pros and cons of each of the kernels above by using nvprof with large matrix sizes to validate your posize_ts. Collect your insights in a PDF report and explain them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:00.475818Z",
     "iopub.status.busy": "2025-02-17T11:09:00.475444Z",
     "iopub.status.idle": "2025-02-17T11:09:08.827427Z",
     "shell.execute_reply": "2025-02-17T11:09:08.826314Z",
     "shell.execute_reply.started": "2025-02-17T11:09:00.475768Z"
    },
    "id": "r9GPGdFOh_ma",
    "outputId": "2d2d04a0-e58a-4c27-e122-3086b281f62b",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Source files will be saved in \"C:\\Users\\basim\\AppData\\Local\\Temp\\tmp8oi0o72n\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git 'C:\\Users\\basim\\AppData\\Local\\Temp\\pip-req-build-6dif6js5'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
      "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to c:\\users\\basim\\appdata\\local\\temp\\pip-req-build-6dif6js5\n",
      "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 28f872a2f99a1b201bcd0db14fdbc5a496b9bfd7\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n"
     ]
    }
   ],
   "source": [
    "# Setup cuda environment\n",
    "%pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
    "%load_ext nvcc4jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Testcases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:08.829464Z",
     "iopub.status.busy": "2025-02-17T11:09:08.829104Z",
     "iopub.status.idle": "2025-02-17T11:09:08.837875Z",
     "shell.execute_reply": "2025-02-17T11:09:08.836745Z",
     "shell.execute_reply.started": "2025-02-17T11:09:08.829423Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_matrix_test_cases(num_tests, min_dim, max_dim, min_val, max_val, output_file):\n",
    "    \"\"\"\n",
    "    Generate test cases for matrix addition\n",
    "    Parameters:\n",
    "    - num_tests: number of test cases\n",
    "    - min_dim: minimum dimension (rows/cols)\n",
    "    - max_dim: maximum dimension (rows/cols)\n",
    "    - min_val: minimum value in matrices\n",
    "    - max_val: maximum value in matrices\n",
    "    - output_file: path to output file\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Write number of test cases\n",
    "        f.write(f\"{num_tests}\\n\")\n",
    "        \n",
    "        for _ in range(num_tests):\n",
    "            # Generate random dimensions\n",
    "            rows = np.random.randint(min_dim, max_dim + 1)\n",
    "            cols = np.random.randint(min_dim, max_dim + 1)\n",
    "            \n",
    "            # Write dimensions\n",
    "            f.write(f\"{rows} {cols}\\n\")\n",
    "            \n",
    "            # Generate and write first matrix\n",
    "            matrix1 = np.random.uniform(min_val, max_val, (rows, cols))\n",
    "            for row in matrix1:\n",
    "                f.write(\" \".join(f\"{x:.3f}\" for x in row) + \"\\n\")\n",
    "            \n",
    "            # Generate and write second matrix\n",
    "            matrix2 = np.random.uniform(min_val, max_val, (rows, cols))\n",
    "            for row in matrix2:\n",
    "                f.write(\" \".join(f\"{x:.3f}\" for x in row) + \"\\n\")\n",
    "\n",
    "# Set your parameters here\n",
    "params = {\n",
    "    'num_tests': 5,              # Number of test cases\n",
    "    'min_dim': 2,               # Minimum matrix dimension\n",
    "    'max_dim': 10,               # Maximum matrix dimension\n",
    "    'min_val': -50000000.0,           # Minimum value in matrices\n",
    "    'max_val': 5000000000.0,            # Maximum value in matrices\n",
    "    'output_file': './inputfile.txt'  # Output file name\n",
    "}\n",
    "\n",
    "# Run the generator with the specified parameters\n",
    "if __name__ == \"__main__\":\n",
    "    generate_matrix_test_cases(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CPU Only**\n",
    "# Vector addition in pure C (CPU-only execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:08.840091Z",
     "iopub.status.busy": "2025-02-17T11:09:08.839872Z",
     "iopub.status.idle": "2025-02-17T11:09:08.861102Z",
     "shell.execute_reply": "2025-02-17T11:09:08.860246Z",
     "shell.execute_reply.started": "2025-02-17T11:09:08.840072Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kernel0.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile kernel0.cu   \n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include <assert.h>\n",
    "#include <time.h>\n",
    "\n",
    "#define MAX_ERR 1e-6\n",
    "\n",
    "// Function to perform vector addition\n",
    "void vector_add(double *out, double *a, double *b, size_t  n) {\n",
    "    for (size_t  i = 0; i < n; i++) {\n",
    "        out[i] = a[i] + b[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char* argv[]) {\n",
    "    FILE *file_reading;\n",
    "    int numberOfTests;\n",
    "    size_t rows, cols;\n",
    "    // Open the file in read mode\n",
    "    file_reading = fopen(argv[1], \"r\");\n",
    "    if (file_reading == NULL) {\n",
    "        printf(\"Error opening file!\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    // Read number of tests\n",
    "    fscanf(file_reading, \"%d\",&numberOfTests);\n",
    "for(size_t i=0;i<numberOfTests;i++){\n",
    "    \n",
    "    // Read matrix dimensions\n",
    "    fscanf(file_reading, \"%zu %zu\",&rows, &cols);\n",
    "    // Allocate host matrices\n",
    "    double* A = (double*)malloc(sizeof(double) * rows * cols);\n",
    "    double* B = (double*)malloc(sizeof(double) * rows * cols);\n",
    "    double* C = (double*)malloc(sizeof(double) * rows * cols);\n",
    "\n",
    "    if (A == NULL || B == NULL || C == NULL) {\n",
    "        printf(\"Memory allocation failed!\\n\");\n",
    "        fclose(file_reading);\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    // Read matrices A and B\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        fscanf(file_reading, \"%lf\", &A[i]);\n",
    "    }\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        fscanf(file_reading, \"%lf\", &B[i]);\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    // Start timing\n",
    "    clock_t start = clock();\n",
    "\n",
    "    // Perform vector addition\n",
    "    vector_add(C, A, B, rows * cols);\n",
    "\n",
    "    // End timing\n",
    "    clock_t end = clock();\n",
    "\n",
    "    // Calculate the elapsed time in seconds\n",
    "    double time_spent = (double)(end - start) / CLOCKS_PER_SEC * 1000.0;\n",
    "\n",
    "    printf(\"Time elapsed: %f ms\\n\", time_spent);\n",
    "\n",
    "    // Verification\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        assert(fabs(C[i] - A[i] - B[i]) < MAX_ERR);\n",
    "    }\n",
    "\n",
    "    printf(\"Vector addition completed successfully!\\n\");\n",
    "\n",
    "  \n",
    "    // Write results to output file\n",
    "   // Write results to output file\n",
    "    FILE *file_writing;\n",
    "    file_writing= fopen(argv[2], \"w\"); // Open file for writing\n",
    "    if (file_writing == NULL) {\n",
    "        perror(\"Error opening file\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "\n",
    "    // Write matrix C\n",
    "    for (size_t i = 0; i < rows; i++) {\n",
    "        for (size_t j = 0; j < cols; j++) {\n",
    "              printf(\"%.3lf \", C[i * cols + j]);    \n",
    "            fprintf(file_writing, \"%.3lf \", C[i * cols + j]); // Write double with 2 decimal places\n",
    "        }\n",
    "         printf(\"\\n\");  \n",
    "        fprintf(file_writing, \"\\n\"); // New line after each row\n",
    "    }\n",
    "    fclose(file_writing);\n",
    "\n",
    "\n",
    "    // Free allocated memory\n",
    "    free(A);\n",
    "    free(B);\n",
    "    free(C);\n",
    "}\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:08.862674Z",
     "iopub.status.busy": "2025-02-17T11:09:08.862362Z",
     "iopub.status.idle": "2025-02-17T11:09:10.391461Z",
     "shell.execute_reply": "2025-02-17T11:09:10.390549Z",
     "shell.execute_reply.started": "2025-02-17T11:09:08.862649Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel0.cu\n",
      "tmpxft_00001b88_00000000-10_kernel0.cudafe1.cpp\n",
      "   Creating library kernel0.lib and object kernel0.exp\n",
      "Time elapsed: 0.000000 ms\n",
      "Vector addition completed successfully!\n",
      "6435366487.397 1433178484.549 1510275566.968 1828845876.877 4483950868.614 4166451532.966 7074156538.042 4541242014.452 4837375348.743 8117219560.029 \n",
      "6575081993.646 4886121097.452 4007272978.500 4812473309.278 5173170920.441 846818149.884 9062404273.921 6520157039.148 2726124482.217 5840637726.005 \n",
      "8009372404.035 4441444876.484 5269302642.615 4512346469.820 2819923498.570 4296742355.366 2681748014.299 5074690285.724 6157783623.263 2653662371.780 \n",
      "4151113376.366 9019137420.064 2907495850.631 5218992329.786 6116726160.825 3995332147.349 6218736239.915 3158080352.853 6635297222.719 4046196482.220 \n",
      "3829458124.007 771164488.591 5023396724.300 3939093889.824 3665183783.752 4810321684.818 4053150843.068 5071842735.070 5408255950.289 5519999999.163 \n",
      "5361094170.047 8661846465.107 1760658262.295 4708091841.541 4797400952.902 7130418557.950 5559034200.029 6038905640.509 6143575485.546 2105827621.119 \n",
      "2711240274.821 3438371894.433 4482970018.522 7037642620.151 6511639637.238 6548131124.076 6965477208.452 2486904737.663 4939482629.912 3070156531.701 \n",
      "3714016329.152 2494660031.703 6802210819.632 6881349371.759 5441786007.441 8436251549.750 4623644671.841 1794878768.597 2227071535.590 3217372215.350 \n",
      "Time elapsed: 0.000000 ms\n",
      "Vector addition completed successfully!\n",
      "761213067.824 2511538058.749 5984828332.341 9391841632.707 4204815676.807 6580517731.218 9369776627.030 \n",
      "3637485491.469 5052790127.499 7666186334.888 7902907684.605 1123605453.713 1701990505.936 5545637186.170 \n",
      "6214019548.948 3302138145.943 8614216722.988 4510045924.739 8164505797.788 2288789871.459 3151119934.758 \n",
      "5902274048.062 4618173451.001 1576859150.133 7971786212.831 2675723162.141 4311039097.364 5288495713.933 \n",
      "6078282201.790 4235231782.267 4993234873.776 1440955076.810 5554533638.240 4073563809.191 8189496626.855 \n",
      "5095072681.392 5198931962.607 5956039528.225 7234395352.883 6445426358.161 7352648184.355 7184603140.136 \n",
      "1135122392.011 5966504241.332 4440505011.523 4814178227.628 1956477440.713 4931024316.870 6209808566.133 \n",
      "6764526262.681 4045465559.403 6011357223.802 5192454178.581 5122733288.271 4132624217.360 1372463060.505 \n",
      "2691679316.677 6894050764.471 8082532046.059 3867567830.401 5141832478.331 4911752892.336 5284381173.341 \n",
      "Time elapsed: 0.000000 ms\n",
      "Vector addition completed successfully!\n",
      "3300374591.918 8313587150.963 3722770678.623 5353229735.435 5285507391.865 3581271555.045 8158049158.077 1490736635.474 1316926458.317 \n",
      "1694169144.344 6093724028.741 3772054210.952 7321005090.373 1486438192.207 4152076058.493 4875543284.548 2549411436.797 4103287976.667 \n",
      "4438397122.925 3421946500.582 7292164668.727 4773068523.679 5798608751.632 1398417967.948 6489750365.624 5111061100.557 7636672853.566 \n",
      "6196028395.692 5857685246.327 1258439337.383 3667128297.752 6618239007.060 3257692853.226 8819547543.657 4711882393.938 5192196005.082 \n",
      "6937209446.526 5218511429.952 5060981569.750 4913617396.337 7585326554.484 4880954005.982 3460629499.315 5900342531.609 3814927410.853 \n",
      "6425364187.996 2725958431.788 7232040143.604 9179238488.715 8592621886.467 2868984882.165 2831060042.305 5239745088.839 4026271544.181 \n",
      "2721439013.686 7628971985.869 7892712647.132 5290435449.392 6367458230.121 4039660718.808 8718814106.585 7422855296.206 583953983.006 \n",
      "5968644727.316 2507882636.319 3844788097.152 5064848607.021 4767280796.528 4656258333.251 3810125213.260 4296546420.413 3910788285.776 \n",
      "8735842709.694 1929388076.696 5707585232.183 8465863968.104 2894823680.873 3329859147.697 2780580520.879 1536565273.210 5836021703.002 \n",
      "Time elapsed: 0.000000 ms\n",
      "Vector addition completed successfully!\n",
      "213233863.526 3367811272.706 1376657602.818 \n",
      "6018966047.050 9173534922.594 8481540812.677 \n",
      "5335558716.138 1801948790.553 6398284847.429 \n",
      "4463688786.522 2853217005.765 7583230807.514 \n",
      "5781869321.479 3515802152.626 8165245624.137 \n",
      "1498537462.183 3075417108.919 4940576498.207 \n",
      "5169761300.721 6351200572.239 7299581078.417 \n",
      "6708656126.687 8677950999.304 4075768469.990 \n",
      "4221191865.154 3224299925.325 2460556115.643 \n",
      "5828683597.164 4431646967.095 7463764528.801 \n",
      "Time elapsed: 0.000000 ms\n",
      "Vector addition completed successfully!\n",
      "7949955341.998 5155542545.144 5358607835.766 6305562056.000 835230146.178 5499518424.353 \n",
      "6506006639.108 1500406476.312 4537344650.210 7894487118.232 1565467801.948 1708371606.834 \n",
      "1848141973.997 5866024405.197 8012521851.745 8571619761.109 2563769862.090 1542424956.133 \n"
     ]
    }
   ],
   "source": [
    "# Compile the CUDA program\n",
    "!nvcc kernel0.cu -o kernel0.exe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.000000 ms\n",
      "Vector addition completed successfully!\n",
      "6435366487.397 1433178484.549 1510275566.968 1828845876.877 4483950868.614 4166451532.966 7074156538.042 4541242014.452 4837375348.743 8117219560.029 \n",
      "6575081993.646 4886121097.452 4007272978.500 4812473309.278 5173170920.441 846818149.884 9062404273.921 6520157039.148 2726124482.217 5840637726.005 \n",
      "8009372404.035 4441444876.484 5269302642.615 4512346469.820 2819923498.570 4296742355.366 2681748014.299 5074690285.724 6157783623.263 2653662371.780 \n",
      "4151113376.366 9019137420.064 2907495850.631 5218992329.786 6116726160.825 3995332147.349 6218736239.915 3158080352.853 6635297222.719 4046196482.220 \n",
      "3829458124.007 771164488.591 5023396724.300 3939093889.824 3665183783.752 4810321684.818 4053150843.068 5071842735.070 5408255950.289 5519999999.163 \n",
      "5361094170.047 8661846465.107 1760658262.295 4708091841.541 4797400952.902 7130418557.950 5559034200.029 6038905640.509 6143575485.546 2105827621.119 \n",
      "2711240274.821 3438371894.433 4482970018.522 7037642620.151 6511639637.238 6548131124.076 6965477208.452 2486904737.663 4939482629.912 3070156531.701 \n",
      "3714016329.152 2494660031.703 6802210819.632 6881349371.759 5441786007.441 8436251549.750 4623644671.841 1794878768.597 2227071535.590 3217372215.350 \n",
      "Time elapsed: 0.000000 ms\n",
      "Vector addition completed successfully!\n",
      "761213067.824 2511538058.749 5984828332.341 9391841632.707 4204815676.807 6580517731.218 9369776627.030 \n",
      "3637485491.469 5052790127.499 7666186334.888 7902907684.605 1123605453.713 1701990505.936 5545637186.170 \n",
      "6214019548.948 3302138145.943 8614216722.988 4510045924.739 8164505797.788 2288789871.459 3151119934.758 \n",
      "5902274048.062 4618173451.001 1576859150.133 7971786212.831 2675723162.141 4311039097.364 5288495713.933 \n",
      "6078282201.790 4235231782.267 4993234873.776 1440955076.810 5554533638.240 4073563809.191 8189496626.855 \n",
      "5095072681.392 5198931962.607 5956039528.225 7234395352.883 6445426358.161 7352648184.355 7184603140.136 \n",
      "1135122392.011 5966504241.332 4440505011.523 4814178227.628 1956477440.713 4931024316.870 6209808566.133 \n",
      "6764526262.681 4045465559.403 6011357223.802 5192454178.581 5122733288.271 4132624217.360 1372463060.505 \n",
      "2691679316.677 6894050764.471 8082532046.059 3867567830.401 5141832478.331 4911752892.336 5284381173.341 \n",
      "Time elapsed: 0.000000 ms\n",
      "Vector addition completed successfully!\n",
      "3300374591.918 8313587150.963 3722770678.623 5353229735.435 5285507391.865 3581271555.045 8158049158.077 1490736635.474 1316926458.317 \n",
      "1694169144.344 6093724028.741 3772054210.952 7321005090.373 1486438192.207 4152076058.493 4875543284.548 2549411436.797 4103287976.667 \n",
      "4438397122.925 3421946500.582 7292164668.727 4773068523.679 5798608751.632 1398417967.948 6489750365.624 5111061100.557 7636672853.566 \n",
      "6196028395.692 5857685246.327 1258439337.383 3667128297.752 6618239007.060 3257692853.226 8819547543.657 4711882393.938 5192196005.082 \n",
      "6937209446.526 5218511429.952 5060981569.750 4913617396.337 7585326554.484 4880954005.982 3460629499.315 5900342531.609 3814927410.853 \n",
      "6425364187.996 2725958431.788 7232040143.604 9179238488.715 8592621886.467 2868984882.165 2831060042.305 5239745088.839 4026271544.181 \n",
      "2721439013.686 7628971985.869 7892712647.132 5290435449.392 6367458230.121 4039660718.808 8718814106.585 7422855296.206 583953983.006 \n",
      "5968644727.316 2507882636.319 3844788097.152 5064848607.021 4767280796.528 4656258333.251 3810125213.260 4296546420.413 3910788285.776 \n",
      "8735842709.694 1929388076.696 5707585232.183 8465863968.104 2894823680.873 3329859147.697 2780580520.879 1536565273.210 5836021703.002 \n",
      "Time elapsed: 0.000000 ms\n",
      "Vector addition completed successfully!\n",
      "213233863.526 3367811272.706 1376657602.818 \n",
      "6018966047.050 9173534922.594 8481540812.677 \n",
      "5335558716.138 1801948790.553 6398284847.429 \n",
      "4463688786.522 2853217005.765 7583230807.514 \n",
      "5781869321.479 3515802152.626 8165245624.137 \n",
      "1498537462.183 3075417108.919 4940576498.207 \n",
      "5169761300.721 6351200572.239 7299581078.417 \n",
      "6708656126.687 8677950999.304 4075768469.990 \n",
      "4221191865.154 3224299925.325 2460556115.643 \n",
      "5828683597.164 4431646967.095 7463764528.801 \n",
      "Time elapsed: 0.000000 ms\n",
      "Vector addition completed successfully!\n",
      "7949955341.998 5155542545.144 5358607835.766 6305562056.000 835230146.178 5499518424.353 \n",
      "6506006639.108 1500406476.312 4537344650.210 7894487118.232 1565467801.948 1708371606.834 \n",
      "1848141973.997 5866024405.197 8012521851.745 8571619761.109 2563769862.090 1542424956.133 \n"
     ]
    }
   ],
   "source": [
    "# Run the executable (Windows style)\n",
    "!.\\kernel0.exe inputfile.txt outputfile_cpu.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For profiling with nvprof (Windows style)\n",
    "!nvprof .\\kernel0.exe inputfile.txt outputfile_cpu.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kernel1: each thread produces one output matrix element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:10.393024Z",
     "iopub.status.busy": "2025-02-17T11:09:10.392688Z",
     "iopub.status.idle": "2025-02-17T11:09:10.399670Z",
     "shell.execute_reply": "2025-02-17T11:09:10.398888Z",
     "shell.execute_reply.started": "2025-02-17T11:09:10.392993Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kernel1.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile kernel1.cu   \n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include <assert.h>\n",
    "#include \"cuda_runtime.h\"\n",
    "#include \"device_launch_parameters.h\"\n",
    "#include <fstream>\n",
    "#include <iostream>\n",
    "#include <sstream>\n",
    "#define MAX_ERR 1e-6\n",
    "__global__ void matrixAddKernel1(double* C, double* A, double* B, size_t rows, size_t cols) {\n",
    "    size_t row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    size_t col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (row < rows && col < cols) {\n",
    "        size_t idx = row * cols + col;\n",
    "        C[idx] = A[idx] + B[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "cudaError_t addMatricesWithCuda(double* C, double* A, double* B, size_t rows, size_t cols) {\n",
    "    double* dev_A = nullptr;\n",
    "    double* dev_B = nullptr;\n",
    "    double* dev_C = nullptr;\n",
    "    cudaError_t cudaStatus;\n",
    "\n",
    "    // Allocate GPU buffers\n",
    "    size_t size = rows * cols * sizeof(double);  // Changed from size_t to double\n",
    "    \n",
    "    cudaStatus = cudaMalloc((void**)&dev_C, size);\n",
    "    \n",
    "    cudaStatus = cudaMalloc((void**)&dev_A, size);\n",
    "\n",
    "    cudaStatus = cudaMalloc((void**)&dev_B, size);\n",
    "\n",
    "    // Copy input matrices from host memory to GPU buffers\n",
    "    cudaStatus = cudaMemcpy(dev_A, A, size, cudaMemcpyHostToDevice);    \n",
    "    cudaStatus = cudaMemcpy(dev_B, B, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Launch kernel\n",
    "    dim3 threadsPerBlock(16, 16); // i just did what Ta and cuda said the best to use\n",
    "    dim3 numBlocks((cols + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
    "                   (rows + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
    "    \n",
    "    matrixAddKernel1<<<numBlocks, threadsPerBlock>>>(dev_C, dev_A, dev_B, rows, cols);\n",
    "\n",
    "    // Copy output matrix from GPU buffer to host memory\n",
    "    cudaStatus = cudaMemcpy(C, dev_C, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    return cudaStatus;\n",
    "}\n",
    "\n",
    "int main(int argc, char* argv[]) {\n",
    "\n",
    "    FILE *file_reading;\n",
    "    int numberOfTests;\n",
    "    size_t  rows, cols;\n",
    "    // Open the file in read mode\n",
    "    file_reading = fopen(argv[1], \"r\");\n",
    "    if (file_reading == NULL) {\n",
    "        printf(\"Error opening file!\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    // Read number of tests\n",
    "    fscanf(file_reading, \"%d\",&numberOfTests);\n",
    "for(size_t i=0;i<numberOfTests;i++){\n",
    "    \n",
    "    // Read matrix dimensions\n",
    "    fscanf(file_reading, \"%zu %zu\", &rows, &cols);\n",
    "\n",
    "    // Allocate host matrices\n",
    "    double* A = (double*)malloc(sizeof(double) * rows * cols);  // Changed from size_t to double\n",
    "    double* B = (double*)malloc(sizeof(double) * rows * cols);\n",
    "    double* C = (double*)malloc(sizeof(double) * rows * cols);\n",
    "\n",
    "    // Read matrices A and B\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        fscanf(file_reading, \"%lf\", &A[i]);\n",
    "    }\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        fscanf(file_reading, \"%lf\", &B[i]);\n",
    "    }\n",
    "    \n",
    " \n",
    "\n",
    "    // Add matrices using CUDA\n",
    "    cudaError_t cudaStatus = addMatricesWithCuda(C, A, B, rows, cols);\n",
    "\n",
    "    // Verification\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        assert(fabs(C[i] - A[i] - B[i]) < MAX_ERR);\n",
    "    }\n",
    "\n",
    "    printf(\"Vector addition completed successfully!\\n\");\n",
    "\n",
    "    // Write results to output file\n",
    "    FILE *file_writing;\n",
    "    file_writing= fopen(argv[2], \"w\"); // Open file for writing\n",
    "    if (file_writing == NULL) {\n",
    "        perror(\"Error opening file\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "\n",
    "    // Write matrix C\n",
    "    for (size_t i = 0; i < rows; i++) {\n",
    "        for (size_t j = 0; j < cols; j++) {\n",
    "              printf(\"%.3f \", C[i * cols + j]);    \n",
    "            fprintf(file_writing, \"%.3f \", C[i * cols + j]); // Write double with 2 decimal places\n",
    "        }\n",
    "         printf(\"\\n\");  \n",
    "        fprintf(file_writing, \"\\n\"); // New line after each row\n",
    "    }\n",
    "    fclose(file_writing);\n",
    "\n",
    "\n",
    "    // Cleanup\n",
    "    free(A);\n",
    "    free(B);\n",
    "    free(C);\n",
    "}\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:10.400617Z",
     "iopub.status.busy": "2025-02-17T11:09:10.400423Z",
     "iopub.status.idle": "2025-02-17T11:09:12.966248Z",
     "shell.execute_reply": "2025-02-17T11:09:12.965410Z",
     "shell.execute_reply.started": "2025-02-17T11:09:10.400599Z"
    },
    "id": "vmzESAnuV15c",
    "outputId": "5725348d-ad4c-4c8d-c43c-f993c9ce997d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compile the CUDA program\n",
    "!nvcc kernel1.cu -o kernel1.exe\n",
    "\n",
    "# Run the executable (Windows style)\n",
    "!.\\kernel1.exe inputfile.txt outputfile_cpu.txt\n",
    "\n",
    "# perfomance for cuda is depricacted but can be used in kaggle notebook\n",
    "# !nvprof .\\kernel1.exe inputfile.txt outputfile_cpu.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==PROF== Connected to process 22208 (E:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_2_Notebook_Solution\\kernel1.exe)\n",
      "==PROF== Profiling \"matrixAddKernel1\" - 0: 0%....50%....100% - 1 pass\n",
      "==PROF== Profiling \"matrixAddKernel1\" - 1: 0%....50%....100% - 1 pass\n",
      "==PROF== Profiling \"matrixAddKernel1\" - 2: 0%....50%....100% - 1 pass\n",
      "==PROF== Profiling \"matrixAddKernel1\" - 3: 0%....50%....100% - 1 pass\n",
      "==PROF== Profiling \"matrixAddKernel1\" - 4: 0%....50%....100% - 1 pass\n",
      "Vector addition completed successfully!\n",
      "6435366487.397 1433178484.549 1510275566.968 1828845876.877 4483950868.614 4166451532.966 7074156538.042 4541242014.452 4837375348.743 8117219560.029 \n",
      "6575081993.646 4886121097.452 4007272978.500 4812473309.278 5173170920.441 846818149.884 9062404273.921 6520157039.148 2726124482.217 5840637726.005 \n",
      "8009372404.035 4441444876.484 5269302642.615 4512346469.820 2819923498.570 4296742355.366 2681748014.299 5074690285.724 6157783623.263 2653662371.780 \n",
      "4151113376.366 9019137420.064 2907495850.631 5218992329.786 6116726160.825 3995332147.349 6218736239.915 3158080352.853 6635297222.719 4046196482.220 \n",
      "3829458124.007 771164488.591 5023396724.300 3939093889.824 3665183783.752 4810321684.818 4053150843.068 5071842735.070 5408255950.289 5519999999.163 \n",
      "5361094170.047 8661846465.107 1760658262.295 4708091841.541 4797400952.902 7130418557.950 5559034200.029 6038905640.509 6143575485.546 2105827621.119 \n",
      "2711240274.821 3438371894.433 4482970018.522 7037642620.151 6511639637.238 6548131124.076 6965477208.452 2486904737.663 4939482629.912 3070156531.701 \n",
      "3714016329.152 2494660031.703 6802210819.632 6881349371.759 5441786007.441 8436251549.750 4623644671.841 1794878768.597 2227071535.590 3217372215.350 \n",
      "Vector addition completed successfully!\n",
      "761213067.824 2511538058.749 5984828332.341 9391841632.707 4204815676.807 6580517731.218 9369776627.030 \n",
      "3637485491.469 5052790127.499 7666186334.888 7902907684.605 1123605453.713 1701990505.936 5545637186.170 \n",
      "6214019548.948 3302138145.943 8614216722.988 4510045924.739 8164505797.788 2288789871.459 3151119934.758 \n",
      "5902274048.062 4618173451.001 1576859150.133 7971786212.831 2675723162.141 4311039097.364 5288495713.933 \n",
      "6078282201.790 4235231782.267 4993234873.776 1440955076.810 5554533638.240 4073563809.191 8189496626.855 \n",
      "5095072681.392 5198931962.607 5956039528.225 7234395352.883 6445426358.161 7352648184.355 7184603140.136 \n",
      "1135122392.011 5966504241.332 4440505011.523 4814178227.628 1956477440.713 4931024316.870 6209808566.133 \n",
      "6764526262.681 4045465559.403 6011357223.802 5192454178.581 5122733288.271 4132624217.360 1372463060.505 \n",
      "2691679316.677 6894050764.471 8082532046.059 3867567830.401 5141832478.331 4911752892.336 5284381173.341 \n",
      "Vector addition completed successfully!\n",
      "3300374591.918 8313587150.963 3722770678.623 5353229735.435 5285507391.865 3581271555.045 8158049158.077 1490736635.474 1316926458.317 \n",
      "1694169144.344 6093724028.741 3772054210.952 7321005090.373 1486438192.207 4152076058.493 4875543284.548 2549411436.797 4103287976.667 \n",
      "4438397122.925 3421946500.582 7292164668.727 4773068523.679 5798608751.632 1398417967.948 6489750365.624 5111061100.557 7636672853.566 \n",
      "6196028395.692 5857685246.327 1258439337.383 3667128297.752 6618239007.060 3257692853.226 8819547543.657 4711882393.938 5192196005.082 \n",
      "6937209446.526 5218511429.952 5060981569.750 4913617396.337 7585326554.484 4880954005.982 3460629499.315 5900342531.609 3814927410.853 \n",
      "6425364187.996 2725958431.788 7232040143.604 9179238488.715 8592621886.467 2868984882.165 2831060042.305 5239745088.839 4026271544.181 \n",
      "2721439013.686 7628971985.869 7892712647.132 5290435449.392 6367458230.121 4039660718.808 8718814106.585 7422855296.206 583953983.006 \n",
      "5968644727.316 2507882636.319 3844788097.152 5064848607.021 4767280796.528 4656258333.251 3810125213.260 4296546420.413 3910788285.776 \n",
      "8735842709.694 1929388076.696 5707585232.183 8465863968.104 2894823680.873 3329859147.697 2780580520.879 1536565273.210 5836021703.002 \n",
      "Vector addition completed successfully!\n",
      "213233863.526 3367811272.706 1376657602.818 \n",
      "6018966047.050 9173534922.594 8481540812.677 \n",
      "5335558716.138 1801948790.553 6398284847.429 \n",
      "4463688786.522 2853217005.765 7583230807.514 \n",
      "5781869321.479 3515802152.626 8165245624.137 \n",
      "1498537462.183 3075417108.919 4940576498.207 \n",
      "5169761300.721 6351200572.239 7299581078.417 \n",
      "6708656126.687 8677950999.304 4075768469.990 \n",
      "4221191865.154 3224299925.325 2460556115.643 \n",
      "5828683597.164 4431646967.095 7463764528.801 \n",
      "Vector addition completed successfully!\n",
      "7949955341.998 5155542545.144 5358607835.766 6305562056.000 835230146.178 5499518424.353 \n",
      "6506006639.108 1500406476.312 4537344650.210 7894487118.232 1565467801.948 1708371606.834 \n",
      "1848141973.997 5866024405.197 8012521851.745 8571619761.109 2563769862.090 1542424956.133 \n",
      "==PROF== Disconnected from process 22208\n",
      "[22208] kernel1.exe@127.0.0.1\n",
      "  matrixAddKernel1(double *, double *, double *, unsigned long long, unsigned long long) (1, 1, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.9\n",
      "    Section: Command line profiler metrics\n",
      "    ---------------------- ----------- ------------\n",
      "    Metric Name            Metric Unit Metric Value\n",
      "    ---------------------- ----------- ------------\n",
      "    gpu__time_duration.avg          us         2.72\n",
      "    gpu__time_duration.max          us         2.72\n",
      "    gpu__time_duration.min          us         2.72\n",
      "    gpu__time_duration.sum          us         2.72\n",
      "    ---------------------- ----------- ------------\n",
      "\n",
      "  matrixAddKernel1(double *, double *, double *, unsigned long long, unsigned long long) (1, 1, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.9\n",
      "    Section: Command line profiler metrics\n",
      "    ---------------------- ----------- ------------\n",
      "    Metric Name            Metric Unit Metric Value\n",
      "    ---------------------- ----------- ------------\n",
      "    gpu__time_duration.avg          us         2.11\n",
      "    gpu__time_duration.max          us         2.11\n",
      "    gpu__time_duration.min          us         2.11\n",
      "    gpu__time_duration.sum          us         2.11\n",
      "    ---------------------- ----------- ------------\n",
      "\n",
      "  matrixAddKernel1(double *, double *, double *, unsigned long long, unsigned long long) (1, 1, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.9\n",
      "    Section: Command line profiler metrics\n",
      "    ---------------------- ----------- ------------\n",
      "    Metric Name            Metric Unit Metric Value\n",
      "    ---------------------- ----------- ------------\n",
      "    gpu__time_duration.avg          us         2.11\n",
      "    gpu__time_duration.max          us         2.11\n",
      "    gpu__time_duration.min          us         2.11\n",
      "    gpu__time_duration.sum          us         2.11\n",
      "    ---------------------- ----------- ------------\n",
      "\n",
      "  matrixAddKernel1(double *, double *, double *, unsigned long long, unsigned long long) (1, 1, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.9\n",
      "    Section: Command line profiler metrics\n",
      "    ---------------------- ----------- ------------\n",
      "    Metric Name            Metric Unit Metric Value\n",
      "    ---------------------- ----------- ------------\n",
      "    gpu__time_duration.avg          us         2.11\n",
      "    gpu__time_duration.max          us         2.11\n",
      "    gpu__time_duration.min          us         2.11\n",
      "    gpu__time_duration.sum          us         2.11\n",
      "    ---------------------- ----------- ------------\n",
      "\n",
      "  matrixAddKernel1(double *, double *, double *, unsigned long long, unsigned long long) (1, 1, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.9\n",
      "    Section: Command line profiler metrics\n",
      "    ---------------------- ----------- ------------\n",
      "    Metric Name            Metric Unit Metric Value\n",
      "    ---------------------- ----------- ------------\n",
      "    gpu__time_duration.avg          us         2.05\n",
      "    gpu__time_duration.max          us         2.05\n",
      "    gpu__time_duration.min          us         2.05\n",
      "    gpu__time_duration.sum          us         2.05\n",
      "    ---------------------- ----------- ------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For profiling with nvprof (Windows style) the new one  for system-level profiling\n",
    "# !nsys profile --stats=true .\\kernel1.exe inputfile.txt outputfile_cpu.txt\n",
    "# # , for kernel details using Nsight Compute:\n",
    "# !ncu --set full .\\kernel1 inputfile.txt outputfile_cpu.txt\n",
    "!ncu --metrics gpu__time_duration .\\kernel1.exe inputfile.txt outputfile_cpu.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kernel2: each thread produces one output matrix row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:12.967571Z",
     "iopub.status.busy": "2025-02-17T11:09:12.967270Z",
     "iopub.status.idle": "2025-02-17T11:09:12.973841Z",
     "shell.execute_reply": "2025-02-17T11:09:12.972954Z",
     "shell.execute_reply.started": "2025-02-17T11:09:12.967548Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kernel2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile kernel2.cu   \n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include <assert.h>\n",
    "#include \"cuda_runtime.h\"\n",
    "#include \"device_launch_parameters.h\"\n",
    "#include <fstream>\n",
    "#include <iostream>\n",
    "#include <sstream>\n",
    "#define MAX_ERR 1e-6\n",
    "__global__ void matrixAddKernel1(double* C, double* A, double* B, size_t rows, size_t cols) {\n",
    "    size_t row = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (row < rows) {\n",
    "        for(size_t col =0 ; col < cols; col++){\n",
    "              size_t idx = row * cols + col;\n",
    "            C[idx] = A[idx] + B[idx];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "cudaError_t addMatricesWithCuda(double* C, double* A, double* B, size_t rows, size_t cols) {\n",
    "    double* dev_A = nullptr;\n",
    "    double* dev_B = nullptr;\n",
    "    double* dev_C = nullptr;\n",
    "    cudaError_t cudaStatus;\n",
    "\n",
    "    // Allocate GPU buffers\n",
    "    size_t size = rows * cols * sizeof(double);  // Changed from size_t to double\n",
    "    \n",
    "    cudaStatus = cudaMalloc((void**)&dev_C, size);\n",
    "    \n",
    "    cudaStatus = cudaMalloc((void**)&dev_A, size);\n",
    "\n",
    "    cudaStatus = cudaMalloc((void**)&dev_B, size);\n",
    "\n",
    "    // Copy input matrices from host memory to GPU buffers\n",
    "    cudaStatus = cudaMemcpy(dev_A, A, size, cudaMemcpyHostToDevice);    \n",
    "    cudaStatus = cudaMemcpy(dev_B, B, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Launch kernel\n",
    "    dim3 threadsPerBlock(16, 16); // i just did what Ta and cuda said the best to use\n",
    "    dim3 numBlocks((cols + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
    "                   (rows + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
    "    \n",
    "    matrixAddKernel1<<<numBlocks, threadsPerBlock>>>(dev_C, dev_A, dev_B, rows, cols);\n",
    "\n",
    "    // Copy output matrix from GPU buffer to host memory\n",
    "    cudaStatus = cudaMemcpy(C, dev_C, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    return cudaStatus;\n",
    "}\n",
    "\n",
    "int main(int argc, char* argv[]) {\n",
    "\n",
    "    FILE *file_reading;\n",
    "    int numberOfTests;\n",
    "    size_t  rows, cols;\n",
    "    // Open the file in read mode\n",
    "    file_reading = fopen(argv[1], \"r\");\n",
    "    if (file_reading == NULL) {\n",
    "        printf(\"Error opening file!\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    // Read number of tests\n",
    "    fscanf(file_reading, \"%d\",&numberOfTests);\n",
    "for(size_t i=0;i<numberOfTests;i++){\n",
    "    \n",
    "    // Read matrix dimensions\n",
    "    fscanf(file_reading, \"%zu %zu\", &rows, &cols);\n",
    "\n",
    "    // Allocate host matrices\n",
    "    double* A = (double*)malloc(sizeof(double) * rows * cols);  // Changed from size_t to double\n",
    "    double* B = (double*)malloc(sizeof(double) * rows * cols);\n",
    "    double* C = (double*)malloc(sizeof(double) * rows * cols);\n",
    "\n",
    "    // Read matrices A and B\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        fscanf(file_reading, \"%lf\", &A[i]);\n",
    "    }\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        fscanf(file_reading, \"%lf\", &B[i]);\n",
    "    }\n",
    "    \n",
    " \n",
    "\n",
    "    // Add matrices using CUDA\n",
    "    cudaError_t cudaStatus = addMatricesWithCuda(C, A, B, rows, cols);\n",
    "\n",
    "    // Verification\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        assert(fabs(C[i] - A[i] - B[i]) < MAX_ERR);\n",
    "    }\n",
    "\n",
    "    printf(\"Vector addition completed successfully!\\n\");\n",
    "\n",
    "    // Write results to output file\n",
    "    FILE *file_writing;\n",
    "    file_writing= fopen(argv[2], \"w\"); // Open file for writing\n",
    "    if (file_writing == NULL) {\n",
    "        perror(\"Error opening file\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "\n",
    "    // Write matrix C\n",
    "    for (size_t i = 0; i < rows; i++) {\n",
    "        for (size_t j = 0; j < cols; j++) {\n",
    "              printf(\"%.3f \", C[i * cols + j]);    \n",
    "            fprintf(file_writing, \"%.3f \", C[i * cols + j]); // Write double with 2 decimal places\n",
    "        }\n",
    "         printf(\"\\n\");  \n",
    "        fprintf(file_writing, \"\\n\"); // New line after each row\n",
    "    }\n",
    "    fclose(file_writing);\n",
    "\n",
    "\n",
    "    // Cleanup\n",
    "    free(A);\n",
    "    free(B);\n",
    "    free(C);\n",
    "}\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:12.974990Z",
     "iopub.status.busy": "2025-02-17T11:09:12.974691Z",
     "iopub.status.idle": "2025-02-17T11:09:15.514352Z",
     "shell.execute_reply": "2025-02-17T11:09:15.513478Z",
     "shell.execute_reply.started": "2025-02-17T11:09:12.974968Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel2.cu\n",
      "tmpxft_00003b94_00000000-10_kernel2.cudafe1.cpp\n",
      "   Creating library kernel2.lib and object kernel2.exp\n"
     ]
    }
   ],
   "source": [
    "!nvcc kernel2.cu -o kernel2\n",
    "!nvprof ./kernel2 inputfile.txt outputfile_kernel2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kernel3: each thread produces one output matrix col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:15.516579Z",
     "iopub.status.busy": "2025-02-17T11:09:15.516312Z",
     "iopub.status.idle": "2025-02-17T11:09:15.522944Z",
     "shell.execute_reply": "2025-02-17T11:09:15.521897Z",
     "shell.execute_reply.started": "2025-02-17T11:09:15.516556Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kernel3.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile kernel3.cu   \n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include <assert.h>\n",
    "#include \"cuda_runtime.h\"\n",
    "#include \"device_launch_parameters.h\"\n",
    "#include <fstream>\n",
    "#include <iostream>\n",
    "#include <sstream>\n",
    "#define MAX_ERR 1e-6\n",
    "__global__ void matrixAddKernel1(double* C, double* A, double* B, size_t rows, size_t cols) {\n",
    "    size_t col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if ( col < cols) {\n",
    "        for(size_t row = 0; row< rows ; row++){\n",
    "            size_t idx = row * cols + col;\n",
    "            C[idx] = A[idx] + B[idx];\n",
    "        }\n",
    "   \n",
    "    }\n",
    "}\n",
    "\n",
    "cudaError_t addMatricesWithCuda(double* C, double* A, double* B, size_t rows, size_t cols) {\n",
    "    double* dev_A = nullptr;\n",
    "    double* dev_B = nullptr;\n",
    "    double* dev_C = nullptr;\n",
    "    cudaError_t cudaStatus;\n",
    "\n",
    "    // Allocate GPU buffers\n",
    "    size_t size = rows * cols * sizeof(double);  // Changed from size_t to double\n",
    "    \n",
    "    cudaStatus = cudaMalloc((void**)&dev_C, size);\n",
    "    \n",
    "    cudaStatus = cudaMalloc((void**)&dev_A, size);\n",
    "\n",
    "    cudaStatus = cudaMalloc((void**)&dev_B, size);\n",
    "\n",
    "    // Copy input matrices from host memory to GPU buffers\n",
    "    cudaStatus = cudaMemcpy(dev_A, A, size, cudaMemcpyHostToDevice);    \n",
    "    cudaStatus = cudaMemcpy(dev_B, B, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Launch kernel\n",
    "    dim3 threadsPerBlock(16, 16); // i just did what Ta and cuda said the best to use\n",
    "    dim3 numBlocks((cols + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
    "                   (rows + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
    "    \n",
    "    matrixAddKernel1<<<numBlocks, threadsPerBlock>>>(dev_C, dev_A, dev_B, rows, cols);\n",
    "\n",
    "    // Copy output matrix from GPU buffer to host memory\n",
    "    cudaStatus = cudaMemcpy(C, dev_C, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    return cudaStatus;\n",
    "}\n",
    "\n",
    "int main(int argc, char* argv[]) {\n",
    "\n",
    "    FILE *file_reading;\n",
    "    int numberOfTests;\n",
    "    size_t  rows, cols;\n",
    "    // Open the file in read mode\n",
    "    file_reading = fopen(argv[1], \"r\");\n",
    "    if (file_reading == NULL) {\n",
    "        printf(\"Error opening file!\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    // Read number of tests\n",
    "    fscanf(file_reading, \"%d\",&numberOfTests);\n",
    "for(size_t i=0;i<numberOfTests;i++){\n",
    "    \n",
    "    // Read matrix dimensions\n",
    "    fscanf(file_reading, \"%zu %zu\", &rows, &cols);\n",
    "\n",
    "    // Allocate host matrices\n",
    "    double* A = (double*)malloc(sizeof(double) * rows * cols);  // Changed from size_t to double\n",
    "    double* B = (double*)malloc(sizeof(double) * rows * cols);\n",
    "    double* C = (double*)malloc(sizeof(double) * rows * cols);\n",
    "\n",
    "    // Read matrices A and B\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        fscanf(file_reading, \"%lf\", &A[i]);\n",
    "    }\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        fscanf(file_reading, \"%lf\", &B[i]);\n",
    "    }\n",
    "    \n",
    " \n",
    "\n",
    "    // Add matrices using CUDA\n",
    "    cudaError_t cudaStatus = addMatricesWithCuda(C, A, B, rows, cols);\n",
    "\n",
    "    // Verification\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        assert(fabs(C[i] - A[i] - B[i]) < MAX_ERR);\n",
    "    }\n",
    "\n",
    "    printf(\"Vector addition completed successfully!\\n\");\n",
    "\n",
    "    // Write results to output file\n",
    "    FILE *file_writing;\n",
    "    file_writing= fopen(argv[2], \"w\"); // Open file for writing\n",
    "    if (file_writing == NULL) {\n",
    "        perror(\"Error opening file\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "\n",
    "    // Write matrix C\n",
    "    for (size_t i = 0; i < rows; i++) {\n",
    "        for (size_t j = 0; j < cols; j++) {\n",
    "            printf(\"%.3f \", C[i * cols + j]);    \n",
    "            fprintf(file_writing, \"%.3f \", C[i * cols + j]); // Write double with 2 decimal places\n",
    "        }\n",
    "        printf(\"\\n\");  \n",
    "        fprintf(file_writing, \"\\n\"); // New line after each row\n",
    "    }\n",
    "    fclose(file_writing);\n",
    "\n",
    "\n",
    "    // Cleanup\n",
    "    free(A);\n",
    "    free(B);\n",
    "    free(C);\n",
    "}\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:15.524342Z",
     "iopub.status.busy": "2025-02-17T11:09:15.524009Z",
     "iopub.status.idle": "2025-02-17T11:09:18.084042Z",
     "shell.execute_reply": "2025-02-17T11:09:18.083151Z",
     "shell.execute_reply.started": "2025-02-17T11:09:15.524310Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel3.cu\n",
      "tmpxft_00001f04_00000000-10_kernel3.cudafe1.cpp\n",
      "   Creating library kernel3.lib and object kernel3.exp\n"
     ]
    }
   ],
   "source": [
    "!nvcc kernel3.cu -o kernel3\n",
    "!nvprof ./kernel3 inputfile.txt outputfile_kernel3.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. It is required to sum all elements in a 3d volume as follows:\n",
    "- First kernel will sum all elements across the z-dimension and produces a 2d matrix\n",
    "- Second kernel will reduce the 2d matrix into a 1d vector\n",
    "- The resulted vector should be reduced int a single element using the CPU\n",
    "- Print \"Kernel {kernel name}\" Started after calling each kernel, what do you notice?\n",
    "\n",
    "example input and output files for the second requirement are attached\n",
    "\n",
    "your code should take two arguments which are the input and output files (you may use c++)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kernel.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile kernel.cu   \n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Kernel to sum across the z-dimension\n",
    "__global__ void sumZDimension(float *input, float *output, int width, int height, int depth) {\n",
    "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "\n",
    "    if (x < width && y < height) {\n",
    "        float sum = 0.0f;\n",
    "        for (int z = 0; z < depth; ++z) {\n",
    "            sum += input[(z * height + y) * width + x];\n",
    "        }\n",
    "        output[y * width + x] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Kernel to reduce 2D matrix to 1D vector\n",
    "__global__ void reduce2DTo1D(float *input, float *output, int width, int height) {\n",
    "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (x < width) {\n",
    "        float sum = 0.0f;\n",
    "        for (int y = 0; y < height; ++y) {\n",
    "            sum += input[y * width + x];\n",
    "        }\n",
    "        output[x] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Function to reduce 1D vector to a single element on the CPU\n",
    "float reduce1DToSingle(float *input, int length) {\n",
    "    float sum = 0.0f;\n",
    "    for (int i = 0; i < length; ++i) {\n",
    "        sum += input[i];\n",
    "    }\n",
    "    return sum;\n",
    "}\n",
    "\n",
    "// Function to read input data from file\n",
    "void readInputFile(const char *filename, float **data, int *width, int *height, int *depth) {\n",
    "    FILE *file = fopen(filename, \"r\");\n",
    "    if (!file) {\n",
    "        fprintf(stderr, \"Error opening file %s\\n\", filename);\n",
    "        exit(EXIT_FAILURE);\n",
    "    }\n",
    "\n",
    "    fscanf(file, \"%d %d %d\", width, height, depth);\n",
    "\n",
    "    int size = (*width) * (*height) * (*depth);\n",
    "    *data = (float *)malloc(size * sizeof(float));\n",
    "\n",
    "    for (int i = 0; i < size; ++i) {\n",
    "        fscanf(file, \"%f\", &(*data)[i]);\n",
    "    }\n",
    "\n",
    "    fclose(file);\n",
    "}\n",
    "\n",
    "// Function to write output data to file\n",
    "void writeOutputFile(const char *filename, float result) {\n",
    "    FILE *file = fopen(filename, \"w\");\n",
    "    if (!file) {\n",
    "        fprintf(stderr, \"Error opening file %s\\n\", filename);\n",
    "        exit(EXIT_FAILURE);\n",
    "    }\n",
    "\n",
    "    fprintf(file, \"%.3f\\n\", result);\n",
    "    fclose(file);\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]) {\n",
    "    if (argc != 3) {\n",
    "        printf(\"Usage: %s <inputfile> <outputfile>\\n\", argv[0]);\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    const char *inputFile = argv[1];\n",
    "    const char *outputFile = argv[2];\n",
    "\n",
    "    // Load input data from file\n",
    "    float *h_input;\n",
    "    int width, height, depth;\n",
    "    readInputFile(inputFile, &h_input, &width, &height, &depth);\n",
    "\n",
    "    // Allocate memory for input and output\n",
    "    float *d_input, *d_output2D, *d_output1D;\n",
    "    cudaMalloc(&d_input, width * height * depth * sizeof(float));\n",
    "    cudaMalloc(&d_output2D, width * height * sizeof(float));\n",
    "    cudaMalloc(&d_output1D, width * sizeof(float));\n",
    "\n",
    "    // Copy input data to device\n",
    "    cudaMemcpy(d_input, h_input, width * height * depth * sizeof(float), cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Define block and grid sizes\n",
    "    dim3 blockSize(16, 16);\n",
    "    dim3 gridSize((width + blockSize.x - 1) / blockSize.x, (height + blockSize.y - 1) / blockSize.y);\n",
    "\n",
    "    // Launch first kernel\n",
    "    printf(\"Kernel sumZDimension Started\\n\");\n",
    "    sumZDimension<<<gridSize, blockSize>>>(d_input, d_output2D, width, height, depth);\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    // Launch second kernel\n",
    "    printf(\"Kernel reduce2DTo1D Started\\n\");\n",
    "    reduce2DTo1D<<<(width + blockSize.x - 1) / blockSize.x, blockSize.x>>>(d_output2D, d_output1D, width, height);\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    // Copy result back to host\n",
    "    float *h_output1D = (float *)malloc(width * sizeof(float));\n",
    "    cudaMemcpy(h_output1D, d_output1D, width * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Reduce 1D vector to a single element on the CPU\n",
    "    float result = reduce1DToSingle(h_output1D, width);\n",
    "\n",
    "    // Save result to output file\n",
    "    writeOutputFile(outputFile, result);\n",
    "\n",
    "    // Free memory\n",
    "    cudaFree(d_input);\n",
    "    cudaFree(d_output2D);\n",
    "    cudaFree(d_output1D);\n",
    "    free(h_input);\n",
    "    free(h_output1D);\n",
    "\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel.cu\n",
      "tmpxft_00003524_00000000-10_kernel.cudafe1.cpp\n",
      "   Creating library kernel.lib and object kernel.exp\n",
      "Kernel sumZDimension Started\n",
      "Kernel reduce2DTo1D Started\n"
     ]
    }
   ],
   "source": [
    "# Compile the CUDA program\n",
    "!nvcc kernel.cu -o kernel.exe\n",
    "\n",
    "# Run the executable (Windows style)\n",
    "!.\\kernel.exe inputfile.txt outputfile_cpu.txt\n",
    "\n",
    "# perfomance for cuda is depricacted but can be used in kaggle notebook\n",
    "# !nvprof .\\kernel.exe inputfile.txt outputfile_cpu.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==PROF== Connected to process 19860 (E:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_2_Notebook_Solution\\kernel.exe)\n",
      "==PROF== Profiling \"sumZDimension\" - 0: 0%....50%....100% - 1 pass\n",
      "==PROF== Profiling \"reduce2DTo1D\" - 1: 0%....50%....100% - 1 pass\n",
      "Kernel sumZDimension Started\n",
      "Kernel reduce2DTo1D Started\n",
      "==PROF== Disconnected from process 19860\n",
      "[19860] kernel.exe@127.0.0.1\n",
      "  sumZDimension(float *, float *, int, int, int) (1, 1, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.9\n",
      "    Section: Command line profiler metrics\n",
      "    ---------------------- ----------- ------------\n",
      "    Metric Name            Metric Unit Metric Value\n",
      "    ---------------------- ----------- ------------\n",
      "    gpu__time_duration.avg          us         2.94\n",
      "    gpu__time_duration.max          us         2.94\n",
      "    gpu__time_duration.min          us         2.94\n",
      "    gpu__time_duration.sum          us         2.94\n",
      "    ---------------------- ----------- ------------\n",
      "\n",
      "  reduce2DTo1D(float *, float *, int, int) (1, 1, 1)x(16, 1, 1), Context 1, Stream 7, Device 0, CC 8.9\n",
      "    Section: Command line profiler metrics\n",
      "    ---------------------- ----------- ------------\n",
      "    Metric Name            Metric Unit Metric Value\n",
      "    ---------------------- ----------- ------------\n",
      "    gpu__time_duration.avg          us         2.50\n",
      "    gpu__time_duration.max          us         2.50\n",
      "    gpu__time_duration.min          us         2.50\n",
      "    gpu__time_duration.sum          us         2.50\n",
      "    ---------------------- ----------- ------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For profiling with nvprof (Windows style) the new one  for system-level profiling\n",
    "# !nsys profile --stats=true .\\kernel0.exe inputfile.txt outputfile_cpu.txt\n",
    "# # , for kernel details using Nsight Compute:\n",
    "# !ncu --set full .\\kernel0 inputfile.txt outputfile_cpu.txt\n",
    "!ncu --metrics gpu__time_duration .\\kernel.exe inputfile.txt outputfile_cpu.txt"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

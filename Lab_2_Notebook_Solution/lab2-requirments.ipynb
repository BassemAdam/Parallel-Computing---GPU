{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DK_zgOn0ryT"
   },
   "source": [
    "# **Lab 2 Basim Sherief 1210207**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czaY5SFEp3Ec"
   },
   "source": [
    "### **Requirement 2**\n",
    "\n",
    "1) Complete the provided matrix addition example, following these cases:\n",
    "        \n",
    "        A.   kernel1: each thread produces one output matrix element\n",
    "        B.   kernel2: each thread produces one output matrix row\n",
    "        C.   kernel3: each thread produces one output matrix column\n",
    "  Analyze the pros and cons of each of the kernels above by using nvprof with large matrix sizes to validate your posize_ts. Collect your insights in a PDF report and explain them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:00.475818Z",
     "iopub.status.busy": "2025-02-17T11:09:00.475444Z",
     "iopub.status.idle": "2025-02-17T11:09:08.827427Z",
     "shell.execute_reply": "2025-02-17T11:09:08.826314Z",
     "shell.execute_reply.started": "2025-02-17T11:09:00.475768Z"
    },
    "id": "r9GPGdFOh_ma",
    "outputId": "2d2d04a0-e58a-4c27-e122-3086b281f62b",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
      "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to c:\\users\\basim\\appdata\\local\\temp\\pip-req-build-w96ql_t7\n",
      "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 28f872a2f99a1b201bcd0db14fdbc5a496b9bfd7\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Source files will be saved in \"C:\\Users\\basim\\AppData\\Local\\Temp\\tmpxkuu53mo\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git 'C:\\Users\\basim\\AppData\\Local\\Temp\\pip-req-build-w96ql_t7'\n"
     ]
    }
   ],
   "source": [
    "# Setup cuda environment\n",
    "%pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
    "%load_ext nvcc4jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Testcases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:08.829464Z",
     "iopub.status.busy": "2025-02-17T11:09:08.829104Z",
     "iopub.status.idle": "2025-02-17T11:09:08.837875Z",
     "shell.execute_reply": "2025-02-17T11:09:08.836745Z",
     "shell.execute_reply.started": "2025-02-17T11:09:08.829423Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_matrix_test_cases(num_tests, min_dim, max_dim, min_val, max_val, output_file):\n",
    "    \"\"\"\n",
    "    Generate test cases for matrix addition\n",
    "    Parameters:\n",
    "    - num_tests: number of test cases\n",
    "    - min_dim: minimum dimension (rows/cols)\n",
    "    - max_dim: maximum dimension (rows/cols)\n",
    "    - min_val: minimum value in matrices\n",
    "    - max_val: maximum value in matrices\n",
    "    - output_file: path to output file\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Write number of test cases\n",
    "        f.write(f\"{num_tests}\\n\")\n",
    "        \n",
    "        for _ in range(num_tests):\n",
    "            # Generate random dimensions\n",
    "            rows = np.random.randint(4096, 4096 + 1)\n",
    "            cols = np.random.randint(256, 256 + 1)\n",
    "            \n",
    "            # Write dimensions\n",
    "            f.write(f\"{rows} {cols}\\n\")\n",
    "            \n",
    "            # Generate and write first matrix\n",
    "            matrix1 = np.random.uniform(min_val, max_val, (rows, cols))\n",
    "            for row in matrix1:\n",
    "                f.write(\" \".join(f\"{x:.3f}\" for x in row) + \"\\n\")\n",
    "            \n",
    "            # Generate and write second matrix\n",
    "            matrix2 = np.random.uniform(min_val, max_val, (rows, cols))\n",
    "            for row in matrix2:\n",
    "                f.write(\" \".join(f\"{x:.3f}\" for x in row) + \"\\n\")\n",
    "\n",
    "# Set your parameters here\n",
    "params = {\n",
    "    'num_tests': 1,              # Number of test cases\n",
    "    'min_dim': 1024,               # Minimum matrix dimension\n",
    "    'max_dim': 1024,               # Maximum matrix dimension\n",
    "    'min_val': -50000000.0,           # Minimum value in matrices\n",
    "    'max_val': 5000000000.0,            # Maximum value in matrices\n",
    "    'output_file': './Input_TestCases/inputfile.txt'  # Output file name\n",
    "}\n",
    "\n",
    "# Run the generator with the specified parameters\n",
    "if __name__ == \"__main__\":\n",
    "    generate_matrix_test_cases(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CPU Only**\n",
    "# Vector addition in pure C (CPU-only execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:08.840091Z",
     "iopub.status.busy": "2025-02-17T11:09:08.839872Z",
     "iopub.status.idle": "2025-02-17T11:09:08.861102Z",
     "shell.execute_reply": "2025-02-17T11:09:08.860246Z",
     "shell.execute_reply.started": "2025-02-17T11:09:08.840072Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kernel0.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile kernel0.cu   \n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include <assert.h>\n",
    "#include <time.h>\n",
    "\n",
    "#define MAX_ERR 1e-6\n",
    "\n",
    "// Function to perform vector addition\n",
    "void vector_add(double *out, double *a, double *b, size_t  n) {\n",
    "    for (size_t  i = 0; i < n; i++) {\n",
    "        out[i] = a[i] + b[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char* argv[]) {\n",
    "    FILE *file_reading;\n",
    "    int numberOfTests;\n",
    "    size_t rows, cols;\n",
    "    // Open the file in read mode\n",
    "    file_reading = fopen(argv[1], \"r\");\n",
    "    if (file_reading == NULL) {\n",
    "        printf(\"Error opening file!\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    // Read number of tests\n",
    "    fscanf(file_reading, \"%d\",&numberOfTests);\n",
    "for(size_t i=0;i<numberOfTests;i++){\n",
    "    \n",
    "    // Read matrix dimensions\n",
    "    fscanf(file_reading, \"%zu %zu\",&rows, &cols);\n",
    "    // Allocate host matrices\n",
    "    double* A = (double*)malloc(sizeof(double) * rows * cols);\n",
    "    double* B = (double*)malloc(sizeof(double) * rows * cols);\n",
    "    double* C = (double*)malloc(sizeof(double) * rows * cols);\n",
    "\n",
    "    if (A == NULL || B == NULL || C == NULL) {\n",
    "        printf(\"Memory allocation failed!\\n\");\n",
    "        fclose(file_reading);\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    // Read matrices A and B\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        fscanf(file_reading, \"%lf\", &A[i]);\n",
    "    }\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        fscanf(file_reading, \"%lf\", &B[i]);\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    // Start timing\n",
    "    clock_t start = clock();\n",
    "\n",
    "    // Perform vector addition\n",
    "    vector_add(C, A, B, rows * cols);\n",
    "\n",
    "    // End timing\n",
    "    clock_t end = clock();\n",
    "\n",
    "    // Calculate the elapsed time in seconds\n",
    "    double time_spent = (double)(end - start) / CLOCKS_PER_SEC * 1000.0;\n",
    "\n",
    "    printf(\"Time elapsed: %f ms\\n\", time_spent);\n",
    "\n",
    "    // Verification\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        assert(fabs(C[i] - A[i] - B[i]) < MAX_ERR);\n",
    "    }\n",
    "\n",
    "    printf(\"Vector addition completed successfully!\\n\");\n",
    "\n",
    "  \n",
    "    // Write results to output file\n",
    "   // Write results to output file\n",
    "    FILE *file_writing;\n",
    "    file_writing= fopen(argv[2], \"w\"); // Open file for writing\n",
    "    if (file_writing == NULL) {\n",
    "        perror(\"Error opening file\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "\n",
    "    // Write matrix C\n",
    "    for (size_t i = 0; i < rows; i++) {\n",
    "        for (size_t j = 0; j < cols; j++) {\n",
    "              // printf(\"%.3lf \", C[i * cols + j]);    \n",
    "            fprintf(file_writing, \"%.3lf \", C[i * cols + j]); // Write double with 2 decimal places\n",
    "        }\n",
    "         // printf(\"\\n\");  \n",
    "        fprintf(file_writing, \"\\n\"); // New line after each row\n",
    "    }\n",
    "    fclose(file_writing);\n",
    "\n",
    "\n",
    "    // Free allocated memory\n",
    "    free(A);\n",
    "    free(B);\n",
    "    free(C);\n",
    "}\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:08.862674Z",
     "iopub.status.busy": "2025-02-17T11:09:08.862362Z",
     "iopub.status.idle": "2025-02-17T11:09:10.391461Z",
     "shell.execute_reply": "2025-02-17T11:09:10.390549Z",
     "shell.execute_reply.started": "2025-02-17T11:09:08.862649Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel0.cu\n",
      "tmpxft_0000514c_00000000-10_kernel0.cudafe1.cpp\n",
      "   Creating library kernel0.lib and object kernel0.exp\n"
     ]
    }
   ],
   "source": [
    "# Compile the CUDA program\n",
    "!nvcc kernel0.cu -o kernel0.exe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.000000 ms\n",
      "Vector addition completed successfully!\n",
      "Time elapsed: 0.000000 ms\n",
      "Vector addition completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Run the executable (Windows style)\n",
    "!.\\kernel0.exe inputfile.txt outputfile_cpu.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For profiling with nvprof (Windows style)\n",
    "!nvprof .\\kernel0.exe inputfile.txt outputfile_cpu.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kernel1: each thread produces one output matrix element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:10.393024Z",
     "iopub.status.busy": "2025-02-17T11:09:10.392688Z",
     "iopub.status.idle": "2025-02-17T11:09:10.399670Z",
     "shell.execute_reply": "2025-02-17T11:09:10.398888Z",
     "shell.execute_reply.started": "2025-02-17T11:09:10.392993Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kernel1.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile kernel1.cu   \n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include <assert.h>\n",
    "#include \"cuda_runtime.h\"\n",
    "#include \"device_launch_parameters.h\"\n",
    "#include <fstream>\n",
    "#include <iostream>\n",
    "#include <sstream>\n",
    "#define MAX_ERR 1e-6\n",
    "__global__ void matrixAddKernel1(double* C, double* A, double* B, size_t rows, size_t cols) {\n",
    "    size_t row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    size_t col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (row < rows && col < cols) {\n",
    "        size_t idx = row * cols + col;\n",
    "        C[idx] = A[idx] + B[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "cudaError_t addMatricesWithCuda(double* C, double* A, double* B, size_t rows, size_t cols) {\n",
    "    double* dev_A = nullptr;\n",
    "    double* dev_B = nullptr;\n",
    "    double* dev_C = nullptr;\n",
    "    cudaError_t cudaStatus;\n",
    "\n",
    "    // Allocate GPU buffers\n",
    "    size_t size = rows * cols * sizeof(double);  // Changed from size_t to double\n",
    "    \n",
    "    cudaStatus = cudaMalloc((void**)&dev_C, size);\n",
    "    \n",
    "    cudaStatus = cudaMalloc((void**)&dev_A, size);\n",
    "\n",
    "    cudaStatus = cudaMalloc((void**)&dev_B, size);\n",
    "\n",
    "    // Copy input matrices from host memory to GPU buffers\n",
    "    cudaStatus = cudaMemcpy(dev_A, A, size, cudaMemcpyHostToDevice);    \n",
    "    cudaStatus = cudaMemcpy(dev_B, B, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Launch kernel\n",
    "    dim3 threadsPerBlock(16, 16); // i just did what Ta and cuda said the best to use\n",
    "    dim3 numBlocks((cols + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
    "                   (rows + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
    "    \n",
    "    matrixAddKernel1<<<numBlocks, threadsPerBlock>>>(dev_C, dev_A, dev_B, rows, cols);\n",
    "\n",
    "    // Copy output matrix from GPU buffer to host memory\n",
    "    cudaStatus = cudaMemcpy(C, dev_C, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    return cudaStatus;\n",
    "}\n",
    "\n",
    "int main(int argc, char* argv[]) {\n",
    "\n",
    "    FILE *file_reading;\n",
    "    int numberOfTests;\n",
    "    size_t  rows, cols;\n",
    "    // Open the file in read mode\n",
    "    file_reading = fopen(argv[1], \"r\");\n",
    "    if (file_reading == NULL) {\n",
    "        printf(\"Error opening file!\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    // Read number of tests\n",
    "    fscanf(file_reading, \"%d\",&numberOfTests);\n",
    "for(size_t i=0;i<numberOfTests;i++){\n",
    "    \n",
    "    // Read matrix dimensions\n",
    "    fscanf(file_reading, \"%zu %zu\", &rows, &cols);\n",
    "\n",
    "    // Allocate host matrices\n",
    "    double* A = (double*)malloc(sizeof(double) * rows * cols);  // Changed from size_t to double\n",
    "    double* B = (double*)malloc(sizeof(double) * rows * cols);\n",
    "    double* C = (double*)malloc(sizeof(double) * rows * cols);\n",
    "\n",
    "    // Read matrices A and B\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        fscanf(file_reading, \"%lf\", &A[i]);\n",
    "    }\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        fscanf(file_reading, \"%lf\", &B[i]);\n",
    "    }\n",
    "    \n",
    " \n",
    "\n",
    "    // Add matrices using CUDA\n",
    "    cudaError_t cudaStatus = addMatricesWithCuda(C, A, B, rows, cols);\n",
    "\n",
    "    // Verification\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        assert(fabs(C[i] - A[i] - B[i]) < MAX_ERR);\n",
    "    }\n",
    "\n",
    "    printf(\"Vector addition completed successfully!\\n\");\n",
    "\n",
    "    // Write results to output file\n",
    "    FILE *file_writing;\n",
    "    file_writing= fopen(argv[2], \"w\"); // Open file for writing\n",
    "    if (file_writing == NULL) {\n",
    "        perror(\"Error opening file\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "\n",
    "    // Write matrix C\n",
    "    for (size_t i = 0; i < rows; i++) {\n",
    "        for (size_t j = 0; j < cols; j++) {\n",
    "              // printf(\"%.3f \", C[i * cols + j]);    \n",
    "            fprintf(file_writing, \"%.3f \", C[i * cols + j]); // Write double with 2 decimal places\n",
    "        }\n",
    "         // printf(\"\\n\");  \n",
    "        fprintf(file_writing, \"\\n\"); // New line after each row\n",
    "    }\n",
    "    fclose(file_writing);\n",
    "\n",
    "\n",
    "    // Cleanup\n",
    "    free(A);\n",
    "    free(B);\n",
    "    free(C);\n",
    "}\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:10.400617Z",
     "iopub.status.busy": "2025-02-17T11:09:10.400423Z",
     "iopub.status.idle": "2025-02-17T11:09:12.966248Z",
     "shell.execute_reply": "2025-02-17T11:09:12.965410Z",
     "shell.execute_reply.started": "2025-02-17T11:09:10.400599Z"
    },
    "id": "vmzESAnuV15c",
    "outputId": "5725348d-ad4c-4c8d-c43c-f993c9ce997d",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel1.cu\n",
      "tmpxft_00001a4c_00000000-10_kernel1.cudafe1.cpp\n",
      "   Creating library kernel1.lib and object kernel1.exp\n",
      "Vector addition completed successfully!\n",
      "Vector addition completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Compile the CUDA program\n",
    "!nvcc kernel1.cu -o kernel1.exe\n",
    "\n",
    "# Run the executable (Windows style)\n",
    "!.\\kernel1.exe inputfile.txt outputfile_kernel1.txt\n",
    "\n",
    "# perfomance for cuda is depricacted but can be used in kaggle notebook\n",
    "# !nvprof .\\kernel1.exe inputfile.txt outputfile_cpu.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==PROF== Connected to process 16096 (E:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_2_Notebook_Solution\\kernel1.exe)\n",
      "==PROF== Profiling \"matrixAddKernel1\" - 0: 0%....50%....100% - 1 pass\n",
      "==PROF== Profiling \"matrixAddKernel1\" - 1: 0%....50%....100% - 1 pass\n",
      "Vector addition completed successfully!\n",
      "Vector addition completed successfully!\n",
      "==PROF== Disconnected from process 16096\n",
      "[16096] kernel1.exe@127.0.0.1\n",
      "  matrixAddKernel1(double *, double *, double *, unsigned long long, unsigned long long) (1, 1, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.9\n",
      "    Section: Command line profiler metrics\n",
      "    ---------------------- ----------- ------------\n",
      "    Metric Name            Metric Unit Metric Value\n",
      "    ---------------------- ----------- ------------\n",
      "    gpu__time_duration.avg          us         2.62\n",
      "    gpu__time_duration.max          us         2.62\n",
      "    gpu__time_duration.min          us         2.62\n",
      "    gpu__time_duration.sum          us         2.62\n",
      "    ---------------------- ----------- ------------\n",
      "\n",
      "  matrixAddKernel1(double *, double *, double *, unsigned long long, unsigned long long) (1, 1, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.9\n",
      "    Section: Command line profiler metrics\n",
      "    ---------------------- ----------- ------------\n",
      "    Metric Name            Metric Unit Metric Value\n",
      "    ---------------------- ----------- ------------\n",
      "    gpu__time_duration.avg          us         2.11\n",
      "    gpu__time_duration.max          us         2.11\n",
      "    gpu__time_duration.min          us         2.11\n",
      "    gpu__time_duration.sum          us         2.11\n",
      "    ---------------------- ----------- ------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For profiling with nvprof (Windows style) the new one  for system-level profiling\n",
    "# !nsys profile --stats=true .\\kernel1.exe inputfile.txt outputfile_cpu.txt\n",
    "# # , for kernel details using Nsight Compute:\n",
    "# !ncu --set full .\\kernel1 inputfile.txt outputfile_cpu.txt\n",
    "!ncu --metrics gpu__time_duration .\\kernel1.exe inputfile.txt outputfile_cpu.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kernel2: each thread produces one output matrix row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:12.967571Z",
     "iopub.status.busy": "2025-02-17T11:09:12.967270Z",
     "iopub.status.idle": "2025-02-17T11:09:12.973841Z",
     "shell.execute_reply": "2025-02-17T11:09:12.972954Z",
     "shell.execute_reply.started": "2025-02-17T11:09:12.967548Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./cude_kernels/kernel2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./cude_kernels/kernel2.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include <assert.h>\n",
    "#include \"cuda_runtime.h\"\n",
    "#include \"device_launch_parameters.h\"\n",
    "#include <fstream>\n",
    "#include <iostream>\n",
    "#include <sstream>\n",
    "#define MAX_ERR 1e-6\n",
    "__global__ void matrixAddKernel1(double* C, double* A, double* B, size_t rows, size_t cols) {\n",
    "    size_t row = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (row < rows) {\n",
    "        for(size_t col =0 ; col < cols; col++){\n",
    "              size_t idx = row * cols + col;\n",
    "            C[idx] = A[idx] + B[idx];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "cudaError_t addMatricesWithCuda(double* C, double* A, double* B, size_t rows, size_t cols) {\n",
    "    double* dev_A = nullptr;\n",
    "    double* dev_B = nullptr;\n",
    "    double* dev_C = nullptr;\n",
    "    cudaError_t cudaStatus;\n",
    "\n",
    "    // Allocate GPU buffers\n",
    "    size_t size = rows * cols * sizeof(double);  // Changed from size_t to double\n",
    "    \n",
    "    cudaStatus = cudaMalloc((void**)&dev_C, size);\n",
    "    \n",
    "    cudaStatus = cudaMalloc((void**)&dev_A, size);\n",
    "\n",
    "    cudaStatus = cudaMalloc((void**)&dev_B, size);\n",
    "\n",
    "    // Copy input matrices from host memory to GPU buffers\n",
    "    cudaStatus = cudaMemcpy(dev_A, A, size, cudaMemcpyHostToDevice);    \n",
    "    cudaStatus = cudaMemcpy(dev_B, B, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Launch kernel\n",
    "    dim3 threadsPerBlock(16, 16); // i just did what Ta and cuda said the best to use\n",
    "    dim3 numBlocks((cols + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
    "                   (rows + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
    "    \n",
    "    matrixAddKernel1<<<numBlocks, threadsPerBlock>>>(dev_C, dev_A, dev_B, rows, cols);\n",
    "\n",
    "    // Copy output matrix from GPU buffer to host memory\n",
    "    cudaStatus = cudaMemcpy(C, dev_C, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    return cudaStatus;\n",
    "}\n",
    "\n",
    "int main(int argc, char* argv[]) {\n",
    "\n",
    "    FILE *file_reading;\n",
    "    int numberOfTests;\n",
    "    size_t  rows, cols;\n",
    "    // Open the file in read mode\n",
    "    file_reading = fopen(argv[1], \"r\");\n",
    "    if (file_reading == NULL) {\n",
    "        printf(\"Error opening file!\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    // Read number of tests\n",
    "    fscanf(file_reading, \"%d\",&numberOfTests);\n",
    "for(size_t i=0;i<numberOfTests;i++){\n",
    "    \n",
    "    // Read matrix dimensions\n",
    "    fscanf(file_reading, \"%zu %zu\", &rows, &cols);\n",
    "\n",
    "    // Allocate host matrices\n",
    "    double* A = (double*)malloc(sizeof(double) * rows * cols);  // Changed from size_t to double\n",
    "    double* B = (double*)malloc(sizeof(double) * rows * cols);\n",
    "    double* C = (double*)malloc(sizeof(double) * rows * cols);\n",
    "\n",
    "    // Read matrices A and B\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        fscanf(file_reading, \"%lf\", &A[i]);\n",
    "    }\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        fscanf(file_reading, \"%lf\", &B[i]);\n",
    "    }\n",
    "    \n",
    " \n",
    "\n",
    "    // Add matrices using CUDA\n",
    "    cudaError_t cudaStatus = addMatricesWithCuda(C, A, B, rows, cols);\n",
    "\n",
    "    // Verification\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        assert(fabs(C[i] - A[i] - B[i]) < MAX_ERR);\n",
    "    }\n",
    "\n",
    "    printf(\"Vector addition completed successfully!\\n\");\n",
    "\n",
    "    // Write results to output file\n",
    "    FILE *file_writing;\n",
    "    file_writing= fopen(argv[2], \"a\"); // Open file for writing\n",
    "    if (file_writing == NULL) {\n",
    "        perror(\"Error opening file\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "\n",
    "    // Write matrix C\n",
    "    for (size_t i = 0; i < rows; i++) {\n",
    "        for (size_t j = 0; j < cols; j++) {\n",
    "            //  printf(\"%.3f \", C[i * cols + j]);    \n",
    "            fprintf(file_writing, \"%.3f \", C[i * cols + j]); // Write double with 2 decimal places\n",
    "        }\n",
    "        // printf(\"\\n\");  \n",
    "        fprintf(file_writing, \"\\n\"); // New line after each row\n",
    "    }\n",
    "    fclose(file_writing);\n",
    "\n",
    "\n",
    "    // Cleanup\n",
    "    free(A);\n",
    "    free(B);\n",
    "    free(C);\n",
    "}\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:12.974990Z",
     "iopub.status.busy": "2025-02-17T11:09:12.974691Z",
     "iopub.status.idle": "2025-02-17T11:09:15.514352Z",
     "shell.execute_reply": "2025-02-17T11:09:15.513478Z",
     "shell.execute_reply.started": "2025-02-17T11:09:12.974968Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel2.cu\n",
      "tmpxft_00002160_00000000-10_kernel2.cudafe1.cpp\n",
      "   Creating library cude_kernels\\kernel2.lib and object cude_kernels\\kernel2.exp\n"
     ]
    }
   ],
   "source": [
    "!nvcc ./cude_kernels/kernel2.cu -o cude_kernels/kernel2.exe\n",
    "!nvprof ./cude_kernels/kernel2.exe inputfile.txt outputfile_kernel2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==PROF== Connected to process 12396 (E:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_2_Notebook_Solution\\cude_kernels\\kernel2.exe)\n",
      "==PROF== Profiling \"matrixAddKernel1\" - 0: 0%....50%....100% - 1 pass\n",
      "==PROF== Profiling \"matrixAddKernel1\" - 1: 0%....50%....100% - 1 pass\n",
      "Vector addition completed successfully!\n",
      "Vector addition completed successfully!\n",
      "==PROF== Disconnected from process 12396\n",
      "[12396] kernel2.exe@127.0.0.1\n",
      "  matrixAddKernel1(double *, double *, double *, unsigned long long, unsigned long long) (1, 1, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.9\n",
      "    Section: Command line profiler metrics\n",
      "    ---------------------- ----------- ------------\n",
      "    Metric Name            Metric Unit Metric Value\n",
      "    ---------------------- ----------- ------------\n",
      "    gpu__time_duration.avg          us         3.33\n",
      "    gpu__time_duration.max          us         3.33\n",
      "    gpu__time_duration.min          us         3.33\n",
      "    gpu__time_duration.sum          us         3.33\n",
      "    ---------------------- ----------- ------------\n",
      "\n",
      "  matrixAddKernel1(double *, double *, double *, unsigned long long, unsigned long long) (1, 1, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.9\n",
      "    Section: Command line profiler metrics\n",
      "    ---------------------- ----------- ------------\n",
      "    Metric Name            Metric Unit Metric Value\n",
      "    ---------------------- ----------- ------------\n",
      "    gpu__time_duration.avg          us         2.34\n",
      "    gpu__time_duration.max          us         2.34\n",
      "    gpu__time_duration.min          us         2.34\n",
      "    gpu__time_duration.sum          us         2.34\n",
      "    ---------------------- ----------- ------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For profiling with nvprof (Windows style) the new one  for system-level profiling\n",
    "# !nsys profile --stats=true .\\kernel2.exe inputfile.txt outputfile_cpu.txt\n",
    "# # , for kernel details using Nsight Compute:\n",
    "# !ncu --set full .\\kernel2 inputfile.txt outputfile_cpu.txt\n",
    "!ncu --metrics gpu__time_duration .\\cude_kernels\\kernel2.exe inputfile.txt outputfile_kernel2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kernel3: each thread produces one output matrix col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:15.516579Z",
     "iopub.status.busy": "2025-02-17T11:09:15.516312Z",
     "iopub.status.idle": "2025-02-17T11:09:15.522944Z",
     "shell.execute_reply": "2025-02-17T11:09:15.521897Z",
     "shell.execute_reply.started": "2025-02-17T11:09:15.516556Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kernel3.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile kernel3.cu   \n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include <assert.h>\n",
    "#include \"cuda_runtime.h\"\n",
    "#include \"device_launch_parameters.h\"\n",
    "#include <fstream>\n",
    "#include <iostream>\n",
    "#include <sstream>\n",
    "#define MAX_ERR 1e-6\n",
    "__global__ void matrixAddKernel1(double* C, double* A, double* B, size_t rows, size_t cols) {\n",
    "    size_t col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if ( col < cols) {\n",
    "        for(size_t row = 0; row< rows ; row++){\n",
    "            size_t idx = row * cols + col;\n",
    "            C[idx] = A[idx] + B[idx];\n",
    "        }\n",
    "   \n",
    "    }\n",
    "}\n",
    "\n",
    "cudaError_t addMatricesWithCuda(double* C, double* A, double* B, size_t rows, size_t cols) {\n",
    "    double* dev_A = nullptr;\n",
    "    double* dev_B = nullptr;\n",
    "    double* dev_C = nullptr;\n",
    "    cudaError_t cudaStatus;\n",
    "\n",
    "    // Allocate GPU buffers\n",
    "    size_t size = rows * cols * sizeof(double);  // Changed from size_t to double\n",
    "    \n",
    "    cudaStatus = cudaMalloc((void**)&dev_C, size);\n",
    "    \n",
    "    cudaStatus = cudaMalloc((void**)&dev_A, size);\n",
    "\n",
    "    cudaStatus = cudaMalloc((void**)&dev_B, size);\n",
    "\n",
    "    // Copy input matrices from host memory to GPU buffers\n",
    "    cudaStatus = cudaMemcpy(dev_A, A, size, cudaMemcpyHostToDevice);    \n",
    "    cudaStatus = cudaMemcpy(dev_B, B, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Launch kernel\n",
    "    dim3 threadsPerBlock(16, 16); // i just did what Ta and cuda said the best to use\n",
    "    dim3 numBlocks((cols + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
    "                   (rows + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
    "    \n",
    "    matrixAddKernel1<<<numBlocks, threadsPerBlock>>>(dev_C, dev_A, dev_B, rows, cols);\n",
    "\n",
    "    // Copy output matrix from GPU buffer to host memory\n",
    "    cudaStatus = cudaMemcpy(C, dev_C, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    return cudaStatus;\n",
    "}\n",
    "\n",
    "int main(int argc, char* argv[]) {\n",
    "\n",
    "    FILE *file_reading;\n",
    "    int numberOfTests;\n",
    "    size_t  rows, cols;\n",
    "    // Open the file in read mode\n",
    "    file_reading = fopen(argv[1], \"r\");\n",
    "    if (file_reading == NULL) {\n",
    "        printf(\"Error opening file!\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    // Read number of tests\n",
    "    fscanf(file_reading, \"%d\",&numberOfTests);\n",
    "for(size_t i=0;i<numberOfTests;i++){\n",
    "    \n",
    "    // Read matrix dimensions\n",
    "    fscanf(file_reading, \"%zu %zu\", &rows, &cols);\n",
    "\n",
    "    // Allocate host matrices\n",
    "    double* A = (double*)malloc(sizeof(double) * rows * cols);  // Changed from size_t to double\n",
    "    double* B = (double*)malloc(sizeof(double) * rows * cols);\n",
    "    double* C = (double*)malloc(sizeof(double) * rows * cols);\n",
    "\n",
    "    // Read matrices A and B\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        fscanf(file_reading, \"%lf\", &A[i]);\n",
    "    }\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        fscanf(file_reading, \"%lf\", &B[i]);\n",
    "    }\n",
    "    \n",
    " \n",
    "\n",
    "    // Add matrices using CUDA\n",
    "    cudaError_t cudaStatus = addMatricesWithCuda(C, A, B, rows, cols);\n",
    "\n",
    "    // Verification\n",
    "    for (size_t i = 0; i < rows * cols; i++) {\n",
    "        assert(fabs(C[i] - A[i] - B[i]) < MAX_ERR);\n",
    "    }\n",
    "\n",
    "    printf(\"Vector addition completed successfully!\\n\");\n",
    "\n",
    "    // Write results to output file\n",
    "    FILE *file_writing;\n",
    "    file_writing= fopen(argv[2], \"a\"); // Open file for writing\n",
    "    if (file_writing == NULL) {\n",
    "        perror(\"Error opening file\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "\n",
    "    // Write matrix C\n",
    "    for (size_t i = 0; i < rows; i++) {\n",
    "        for (size_t j = 0; j < cols; j++) {\n",
    "           // printf(\"%.3f \", C[i * cols + j]);    \n",
    "            fprintf(file_writing, \"%.3f \", C[i * cols + j]); // Write double with 2 decimal places\n",
    "        }\n",
    "       // printf(\"\\n\");  \n",
    "        fprintf(file_writing, \"\\n\"); // New line after each row\n",
    "    }\n",
    "    fclose(file_writing);\n",
    "\n",
    "\n",
    "    // Cleanup\n",
    "    free(A);\n",
    "    free(B);\n",
    "    free(C);\n",
    "}\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T11:09:15.524342Z",
     "iopub.status.busy": "2025-02-17T11:09:15.524009Z",
     "iopub.status.idle": "2025-02-17T11:09:18.084042Z",
     "shell.execute_reply": "2025-02-17T11:09:18.083151Z",
     "shell.execute_reply.started": "2025-02-17T11:09:15.524310Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel3.cu\n",
      "tmpxft_0000511c_00000000-10_kernel3.cudafe1.cpp\n",
      "   Creating library kernel3.lib and object kernel3.exp\n"
     ]
    }
   ],
   "source": [
    "!nvcc kernel3.cu -o kernel3.exe\n",
    "!nvprof ./kernel3 inputfile.txt outputfile_kernel3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==PROF== Connected to process 20144 (E:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_2_Notebook_Solution\\kernel3.exe)\n",
      "==PROF== Profiling \"matrixAddKernel1\" - 0: 0%....50%....100% - 1 pass\n",
      "==PROF== Profiling \"matrixAddKernel1\" - 1: 0%....50%....100% - 1 pass\n",
      "Vector addition completed successfully!\n",
      "Vector addition completed successfully!\n",
      "==PROF== Disconnected from process 20144\n",
      "[20144] kernel3.exe@127.0.0.1\n",
      "  matrixAddKernel1(double *, double *, double *, unsigned long long, unsigned long long) (1, 1, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.9\n",
      "    Section: Command line profiler metrics\n",
      "    ---------------------- ----------- ------------\n",
      "    Metric Name            Metric Unit Metric Value\n",
      "    ---------------------- ----------- ------------\n",
      "    gpu__time_duration.avg          us         3.26\n",
      "    gpu__time_duration.max          us         3.26\n",
      "    gpu__time_duration.min          us         3.26\n",
      "    gpu__time_duration.sum          us         3.26\n",
      "    ---------------------- ----------- ------------\n",
      "\n",
      "  matrixAddKernel1(double *, double *, double *, unsigned long long, unsigned long long) (1, 1, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.9\n",
      "    Section: Command line profiler metrics\n",
      "    ---------------------- ----------- ------------\n",
      "    Metric Name            Metric Unit Metric Value\n",
      "    ---------------------- ----------- ------------\n",
      "    gpu__time_duration.avg          us         2.37\n",
      "    gpu__time_duration.max          us         2.37\n",
      "    gpu__time_duration.min          us         2.37\n",
      "    gpu__time_duration.sum          us         2.37\n",
      "    ---------------------- ----------- ------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For profiling with nvprof (Windows style) the new one  for system-level profiling\n",
    "# !nsys profile --stats=true .\\kernel3.exe inputfile.txt outputfile_cpu.txt\n",
    "# # , for kernel details using Nsight Compute:\n",
    "# !ncu --set full .\\kernel3 inputfile.txt outputfile_cpu.txt\n",
    "!ncu --metrics gpu__time_duration .\\kernel3.exe inputfile.txt outputfile_kernel3.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. It is required to sum all elements in a 3d volume as follows:\n",
    "- First kernel will sum all elements across the z-dimension and produces a 2d matrix\n",
    "- Second kernel will reduce the 2d matrix into a 1d vector\n",
    "- The resulted vector should be reduced int a single element using the CPU\n",
    "- Print \"Kernel {kernel name}\" Started after calling each kernel, what do you notice?\n",
    "\n",
    "example input and output files for the second requirement are attached\n",
    "\n",
    "your code should take two arguments which are the input and output files (you may use c++)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kernel.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile kernel.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Kernel to sum across the z-dimension\n",
    "__global__ void sumZDimension(double *input, double *output, size_t width, size_t height, size_t depth) {\n",
    "    size_t x = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    size_t y = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "\n",
    "    if (x < width && y < height) {\n",
    "        double sum = 0.0;\n",
    "        for (size_t z = 0; z < depth; ++z) {\n",
    "            sum += input[(z * height + y) * width + x];\n",
    "        }\n",
    "        output[y * width + x] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Kernel to reduce 2D matrix to 1D vector\n",
    "__global__ void reduce2DTo1D(double *input, double *output, size_t width, size_t height) {\n",
    "    size_t x = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (x < width) {\n",
    "        double sum = 0.0;\n",
    "        for (size_t y = 0; y < height; ++y) {\n",
    "            sum += input[y * width + x];\n",
    "        }\n",
    "        output[x] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Function to reduce 1D vector to a single element on the CPU\n",
    "double reduce1DToSingle(double *input, size_t length) {\n",
    "    double sum = 0.0;\n",
    "    for (size_t i = 0; i < length; ++i) {\n",
    "        sum += input[i];\n",
    "    }\n",
    "    return sum;\n",
    "}\n",
    "\n",
    "// Function to read input data from file\n",
    "void readInputFile(const char *filename, double **data, size_t *width, size_t *height, size_t *depth) {\n",
    "    FILE *file = fopen(filename, \"r\");\n",
    "    if (!file) {\n",
    "        fprintf(stderr, \"Error opening file %s\\n\", filename);\n",
    "        exit(EXIT_FAILURE);\n",
    "    }\n",
    "\n",
    "    fscanf(file, \"%zu %zu %zu\", width, height, depth);\n",
    "\n",
    "    size_t size = (*width) * (*height) * (*depth);\n",
    "    *data = (double *)malloc(size * sizeof(double));\n",
    "\n",
    "    for (size_t i = 0; i < size; ++i) {\n",
    "        fscanf(file, \"%lf\", &(*data)[i]);\n",
    "    }\n",
    "\n",
    "    fclose(file);\n",
    "}\n",
    "\n",
    "// Function to write output data to file\n",
    "void writeOutputFile(const char *filename, double result) {\n",
    "    FILE *file = fopen(filename, \"w\");\n",
    "    if (!file) {\n",
    "        fprintf(stderr, \"Error opening file %s\\n\", filename);\n",
    "        exit(EXIT_FAILURE);\n",
    "    }\n",
    "\n",
    "    // Round to 3 decimal places\n",
    "    result = round(result * 1000.0) / 1000.0;\n",
    "\n",
    "    fprintf(file, \"%.3f\\n\", result);\n",
    "    fclose(file);\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]) {\n",
    "    if (argc != 3) {\n",
    "        printf(\"Usage: %s <inputfile> <outputfile>\\n\", argv[0]);\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    const char *inputFile = argv[1];\n",
    "    const char *outputFile = argv[2];\n",
    "\n",
    "    // Load input data from file\n",
    "    double *h_input;\n",
    "    size_t width, height, depth;\n",
    "    readInputFile(inputFile, &h_input, &width, &height, &depth);\n",
    "\n",
    "    // Allocate memory for input and output\n",
    "    double *d_input, *d_output2D, *d_output1D;\n",
    "    cudaMalloc(&d_input, width * height * depth * sizeof(double));\n",
    "    cudaMalloc(&d_output2D, width * height * sizeof(double));\n",
    "    cudaMalloc(&d_output1D, width * sizeof(double));\n",
    "\n",
    "    // Copy input data to device\n",
    "    cudaMemcpy(d_input, h_input, width * height * depth * sizeof(double), cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Define block and grid sizes\n",
    "    dim3 blockSize(16, 16);\n",
    "    dim3 gridSize((width + blockSize.x - 1) / blockSize.x, (height + blockSize.y - 1) / blockSize.y);\n",
    "\n",
    "    // Launch first kernel\n",
    "    printf(\"Kernel sumZDimension Started\\n\");\n",
    "    sumZDimension<<<gridSize, blockSize>>>(d_input, d_output2D, width, height, depth);\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    // Launch second kernel\n",
    "    printf(\"Kernel reduce2DTo1D Started\\n\");\n",
    "    reduce2DTo1D<<<(width + blockSize.x - 1) / blockSize.x, blockSize.x>>>(d_output2D, d_output1D, width, height);\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    // Copy result back to host\n",
    "    double *h_output1D = (double *)malloc(width * sizeof(double));\n",
    "    cudaMemcpy(h_output1D, d_output1D, width * sizeof(double), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Reduce 1D vector to a single element on the CPU\n",
    "    double result = reduce1DToSingle(h_output1D, width);\n",
    "\n",
    "    // Save result to output file\n",
    "    writeOutputFile(outputFile, result);\n",
    "\n",
    "    // Free memory\n",
    "    cudaFree(d_input);\n",
    "    cudaFree(d_output2D);\n",
    "    cudaFree(d_output1D);\n",
    "    free(h_input);\n",
    "    free(h_output1D);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel.cu\n",
      "tmpxft_00000cc0_00000000-10_kernel.cudafe1.cpp\n",
      "   Creating library kernel.lib and object kernel.exp\n",
      "Kernel sumZDimension Started\n",
      "Kernel reduce2DTo1D Started\n"
     ]
    }
   ],
   "source": [
    "# Compile the CUDA program\n",
    "!nvcc kernel.cu -o kernel.exe\n",
    "\n",
    "# Run the executable (Windows style)\n",
    "!.\\kernel.exe inputfile.txt outputfile_cpu.txt\n",
    "\n",
    "# perfomance for cuda is depricacted but can be used in kaggle notebook\n",
    "# !nvprof .\\kernel.exe inputfile.txt outputfile_cpu.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==PROF== Connected to process 3444 (E:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_2_Notebook_Solution\\kernel.exe)\n",
      "==PROF== Profiling \"sumZDimension\" - 0: 0%....50%....100% - 1 pass\n",
      "==PROF== Profiling \"reduce2DTo1D\" - 1: 0%....50%....100% - 1 pass\n",
      "Kernel sumZDimension Started\n",
      "Kernel reduce2DTo1D Started\n",
      "==PROF== Disconnected from process 3444\n",
      "[3444] kernel.exe@127.0.0.1\n",
      "  sumZDimension(double *, double *, unsigned long long, unsigned long long, unsigned long long) (1, 1, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.9\n",
      "    Section: Command line profiler metrics\n",
      "    ---------------------- ----------- ------------\n",
      "    Metric Name            Metric Unit Metric Value\n",
      "    ---------------------- ----------- ------------\n",
      "    gpu__time_duration.avg          us         3.30\n",
      "    gpu__time_duration.max          us         3.30\n",
      "    gpu__time_duration.min          us         3.30\n",
      "    gpu__time_duration.sum          us         3.30\n",
      "    ---------------------- ----------- ------------\n",
      "\n",
      "  reduce2DTo1D(double *, double *, unsigned long long, unsigned long long) (1, 1, 1)x(16, 1, 1), Context 1, Stream 7, Device 0, CC 8.9\n",
      "    Section: Command line profiler metrics\n",
      "    ---------------------- ----------- ------------\n",
      "    Metric Name            Metric Unit Metric Value\n",
      "    ---------------------- ----------- ------------\n",
      "    gpu__time_duration.avg          us         2.14\n",
      "    gpu__time_duration.max          us         2.14\n",
      "    gpu__time_duration.min          us         2.14\n",
      "    gpu__time_duration.sum          us         2.14\n",
      "    ---------------------- ----------- ------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For profiling with nvprof (Windows style) the new one  for system-level profiling\n",
    "# !nsys profile --stats=true .\\kernel0.exe inputfile.txt outputfile_cpu.txt\n",
    "# # , for kernel details using Nsight Compute:\n",
    "# !ncu --set full .\\kernel0 inputfile.txt outputfile_cpu.txt\n",
    "!ncu --metrics gpu__time_duration .\\kernel.exe inputfile.txt outputfile_cpu.txt"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Lab 2 Basim Sherief 1210207**\n","metadata":{"id":"8DK_zgOn0ryT"}},{"cell_type":"markdown","source":"### **Requirement 2**\n\n1) Complete the provided matrix addition example, following these cases:\n        \n        A.   kernel1: each thread produces one output matrix element\n        B.   kernel2: each thread produces one output matrix row\n        C.   kernel3: each thread produces one output matrix column\n  Analyze the pros and cons of each of the kernels above by using nvprof with large matrix sizes to validate your posize_ts. Collect your insights in a PDF report and explain them.\n\n2) Implement a matrixâ€“vector multiplication kernel. Use one thread to calculate an output vector element.\n\nLet both programs read testcases from a .txt file and prsize_t the output to another. Their pathes are to be provided as command line arguments. Sample test file and invoking command are to be attached to the e-learning page.\n\n","metadata":{"id":"czaY5SFEp3Ec"}},{"cell_type":"code","source":"# Setup cuda environment\n!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n%load_ext nvcc4jupyter","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r9GPGdFOh_ma","outputId":"2d2d04a0-e58a-4c27-e122-3086b281f62b","trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:09:00.475444Z","iopub.execute_input":"2025-02-17T11:09:00.475818Z","iopub.status.idle":"2025-02-17T11:09:08.827427Z","shell.execute_reply.started":"2025-02-17T11:09:00.475768Z","shell.execute_reply":"2025-02-17T11:09:08.826314Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-2wds6s2_\n  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-2wds6s2_\n  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 28f872a2f99a1b201bcd0db14fdbc5a496b9bfd7\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nThe nvcc4jupyter extension is already loaded. To reload it, use:\n  %reload_ext nvcc4jupyter\n","output_type":"stream"}],"execution_count":194},{"cell_type":"markdown","source":"**Generate Testcases**","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef generate_matrix_test_cases(num_tests, min_dim, max_dim, min_val, max_val, output_file):\n    \"\"\"\n    Generate test cases for matrix addition\n    Parameters:\n    - num_tests: number of test cases\n    - min_dim: minimum dimension (rows/cols)\n    - max_dim: maximum dimension (rows/cols)\n    - min_val: minimum value in matrices\n    - max_val: maximum value in matrices\n    - output_file: path to output file\n    \"\"\"\n    with open(output_file, 'w') as f:\n        # Write number of test cases\n        f.write(f\"{num_tests}\\n\")\n        \n        for _ in range(num_tests):\n            # Generate random dimensions\n            rows = np.random.randint(min_dim, max_dim + 1)\n            cols = np.random.randint(min_dim, max_dim + 1)\n            \n            # Write dimensions\n            f.write(f\"{rows} {cols}\\n\")\n            \n            # Generate and write first matrix\n            matrix1 = np.random.uniform(min_val, max_val, (rows, cols))\n            for row in matrix1:\n                f.write(\" \".join(f\"{x:.3f}\" for x in row) + \"\\n\")\n            \n            # Generate and write second matrix\n            matrix2 = np.random.uniform(min_val, max_val, (rows, cols))\n            for row in matrix2:\n                f.write(\" \".join(f\"{x:.3f}\" for x in row) + \"\\n\")\n\n# Set your parameters here\nparams = {\n    'num_tests': 5,              # Number of test cases\n    'min_dim': 2,               # Minimum matrix dimension\n    'max_dim': 10,               # Maximum matrix dimension\n    'min_val': -50000000.0,           # Minimum value in matrices\n    'max_val': 5000000000.0,            # Maximum value in matrices\n    'output_file': './inputfile.txt'  # Output file name\n}\n\n# Run the generator with the specified parameters\nif __name__ == \"__main__\":\n    generate_matrix_test_cases(**params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:09:08.829104Z","iopub.execute_input":"2025-02-17T11:09:08.829464Z","iopub.status.idle":"2025-02-17T11:09:08.837875Z","shell.execute_reply.started":"2025-02-17T11:09:08.829423Z","shell.execute_reply":"2025-02-17T11:09:08.836745Z"}},"outputs":[],"execution_count":195},{"cell_type":"markdown","source":"# **CPU Only**\n# Vector addition in pure C (CPU-only execution)","metadata":{}},{"cell_type":"code","source":"%%writefile kernel0.cu   \n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <assert.h>\n#include <time.h>\n\n#define MAX_ERR 1e-6\n\n// Function to perform vector addition\nvoid vector_add(double *out, double *a, double *b, size_t  n) {\n    for (size_t  i = 0; i < n; i++) {\n        out[i] = a[i] + b[i];\n    }\n}\n\nint main(int argc, char* argv[]) {\n    FILE *file_reading;\n    int numberOfTests;\n    size_t rows, cols;\n    // Open the file in read mode\n    file_reading = fopen(argv[1], \"r\");\n    if (file_reading == NULL) {\n        printf(\"Error opening file!\\n\");\n        return 1;\n    }\n\n    // Read number of tests\n    fscanf(file_reading, \"%d\",&numberOfTests);\nfor(size_t i=0;i<numberOfTests;i++){\n    \n    // Read matrix dimensions\n    fscanf(file_reading, \"%zu %zu\",&rows, &cols);\n    // Allocate host matrices\n    double* A = (double*)malloc(sizeof(double) * rows * cols);\n    double* B = (double*)malloc(sizeof(double) * rows * cols);\n    double* C = (double*)malloc(sizeof(double) * rows * cols);\n\n    if (A == NULL || B == NULL || C == NULL) {\n        printf(\"Memory allocation failed!\\n\");\n        fclose(file_reading);\n        return 1;\n    }\n\n    // Read matrices A and B\n    for (size_t i = 0; i < rows * cols; i++) {\n        fscanf(file_reading, \"%lf\", &A[i]);\n    }\n    for (size_t i = 0; i < rows * cols; i++) {\n        fscanf(file_reading, \"%lf\", &B[i]);\n    }\n\n\n\n    // Start timing\n    clock_t start = clock();\n\n    // Perform vector addition\n    vector_add(C, A, B, rows * cols);\n\n    // End timing\n    clock_t end = clock();\n\n    // Calculate the elapsed time in seconds\n    double time_spent = (double)(end - start) / CLOCKS_PER_SEC * 1000.0;\n\n    printf(\"Time elapsed: %f ms\\n\", time_spent);\n\n    // Verification\n    for (size_t i = 0; i < rows * cols; i++) {\n        assert(fabs(C[i] - A[i] - B[i]) < MAX_ERR);\n    }\n\n    printf(\"Vector addition completed successfully!\\n\");\n\n  \n    // Write results to output file\n   // Write results to output file\n    FILE *file_writing;\n    file_writing= fopen(argv[2], \"w\"); // Open file for writing\n    if (file_writing == NULL) {\n        perror(\"Error opening file\");\n        return 1;\n    }\n\n\n    // Write matrix C\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j++) {\n              printf(\"%.3lf \", C[i * cols + j]);    \n            fprintf(file_writing, \"%.3lf \", C[i * cols + j]); // Write double with 2 decimal places\n        }\n         printf(\"\\n\");  \n        fprintf(file_writing, \"\\n\"); // New line after each row\n    }\n    fclose(file_writing);\n\n\n    // Free allocated memory\n    free(A);\n    free(B);\n    free(C);\n}\n    return 0;\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:09:08.839872Z","iopub.execute_input":"2025-02-17T11:09:08.840091Z","iopub.status.idle":"2025-02-17T11:09:08.861102Z","shell.execute_reply.started":"2025-02-17T11:09:08.840072Z","shell.execute_reply":"2025-02-17T11:09:08.860246Z"}},"outputs":[{"name":"stdout","text":"Overwriting kernel0.cu\n","output_type":"stream"}],"execution_count":196},{"cell_type":"code","source":"!nvcc kernel0.cu -o kernel0\n!nvprof ./kernel0 inputfile.txt outputfile_cpu.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:09:08.862362Z","iopub.execute_input":"2025-02-17T11:09:08.862674Z","iopub.status.idle":"2025-02-17T11:09:10.391461Z","shell.execute_reply.started":"2025-02-17T11:09:08.862649Z","shell.execute_reply":"2025-02-17T11:09:10.390549Z"}},"outputs":[{"name":"stdout","text":"Time elapsed: 0.002000 ms\nVector addition completed successfully!\n7682593151.425 9307621257.798 8854249266.964 4087549386.149 3439707194.127 \n8803873489.240 1909966970.166 1397633034.193 7068590033.049 3491590656.183 \n7948104694.498 4313069925.916 4640805840.438 4960592514.210 711771544.461 \nTime elapsed: 0.001000 ms\nVector addition completed successfully!\n4258394483.178 3383874166.151 \n5002761596.659 3018116653.388 \nTime elapsed: 0.001000 ms\nVector addition completed successfully!\n7151195548.145 3552891609.456 2462738634.944 1605793866.303 6614305951.769 6019915126.339 \n7535842869.965 5249547090.566 537876028.792 1643638077.207 4910906587.083 3822890372.163 \n6929633903.204 5232428985.481 6466724766.609 3930741405.756 3848236662.653 3429254488.717 \n5307709439.581 5313845795.434 4157938493.647 4175912989.887 5350863888.465 4186056914.385 \n6584231625.400 7177001344.189 3692395991.829 1718159940.207 3385078105.065 4876807181.588 \n1675273462.793 4077316734.557 2172254967.665 6891091089.804 1255488010.865 4514258137.121 \n5150192358.374 2453545956.993 2898406264.713 5924765059.340 8031780631.099 4437518938.174 \n7041973180.865 5626856646.039 2136559394.513 6125776157.314 7504924846.738 8863035982.280 \nTime elapsed: 0.001000 ms\nVector addition completed successfully!\n5472618452.150 6700861756.825 1463260621.822 5050485860.171 6562264214.086 \n2180099526.028 2888243051.759 6367615612.763 6329286758.001 7033569114.556 \n5429405510.809 4060552646.108 8499007157.396 4492632115.032 6386310368.497 \n3339865153.410 1854019796.952 7678216156.388 4059729476.505 7359809346.039 \n4255264060.569 2751795556.936 4840473731.776 5080877306.628 3240951007.541 \n3224176578.501 5999389017.301 1298708566.853 7079863028.401 8239924443.296 \n6465664689.178 4467780657.949 4086953115.326 3603192768.734 1216704094.892 \nTime elapsed: 0.002000 ms\nVector addition completed successfully!\n3639007801.689 5935415713.825 2675050326.121 2793887395.385 6726445648.216 8468055244.285 4226230808.465 7416185574.472 3977654665.630 3209527380.045 \n4989557339.717 3821461418.679 4330809917.721 5829117885.147 6298808441.558 7973363687.905 2694148743.516 4954767660.630 4440543564.681 4483167532.951 \n4894330920.557 3727594334.974 5224653766.710 2960661878.696 7421593676.418 6020771807.796 3784627923.663 3237279161.715 1743220690.712 7578741951.207 \n2158835150.435 6319090208.618 2892333371.930 5889470852.491 7902941629.144 5079780532.390 6647054589.620 5296080945.978 3135896666.484 6965195188.323 \n6645171353.664 4166315161.758 9409254782.469 5356882340.333 5673106779.568 4275406041.548 6115305554.246 6334959950.531 5815939286.103 2405865113.356 \n5083907867.152 4479339481.234 9313413153.748 5249500377.063 3256985933.155 6664621401.984 3802416404.808 2307426073.236 3102326883.744 4185231943.167 \n5182884742.395 8115873105.219 2448485311.129 2566637685.153 6657898248.850 6614536807.590 4519575511.160 454043159.765 8497162700.206 3966000440.076 \n6959412295.624 1937660083.021 4652299936.033 4291000326.662 4355564149.889 5025664990.960 3556049284.927 8186966032.738 6465618807.097 3780555014.016 \n2475697028.855 5943949122.683 4304446141.010 5841945069.448 8175511786.183 4155457906.136 5963757411.002 4923498312.905 2449569281.521 5611260896.196 \n======== Warning: No profile data collected.\n","output_type":"stream"}],"execution_count":197},{"cell_type":"markdown","source":"# kernel1: each thread produces one output matrix element\n","metadata":{}},{"cell_type":"code","source":"%%writefile kernel1.cu   \n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <assert.h>\n#include \"cuda_runtime.h\"\n#include \"device_launch_parameters.h\"\n#include <fstream>\n#include <iostream>\n#include <sstream>\n#define MAX_ERR 1e-6\n__global__ void matrixAddKernel1(double* C, double* A, double* B, size_t rows, size_t cols) {\n    size_t row = blockIdx.y * blockDim.y + threadIdx.y;\n    size_t col = blockIdx.x * blockDim.x + threadIdx.x;\n    if (row < rows && col < cols) {\n        size_t idx = row * cols + col;\n        C[idx] = A[idx] + B[idx];\n    }\n}\n\ncudaError_t addMatricesWithCuda(double* C, double* A, double* B, size_t rows, size_t cols) {\n    double* dev_A = nullptr;\n    double* dev_B = nullptr;\n    double* dev_C = nullptr;\n    cudaError_t cudaStatus;\n\n    // Allocate GPU buffers\n    size_t size = rows * cols * sizeof(double);  // Changed from size_t to double\n    \n    cudaStatus = cudaMalloc((void**)&dev_C, size);\n    \n    cudaStatus = cudaMalloc((void**)&dev_A, size);\n\n    cudaStatus = cudaMalloc((void**)&dev_B, size);\n\n    // Copy input matrices from host memory to GPU buffers\n    cudaStatus = cudaMemcpy(dev_A, A, size, cudaMemcpyHostToDevice);    \n    cudaStatus = cudaMemcpy(dev_B, B, size, cudaMemcpyHostToDevice);\n\n    // Launch kernel\n    dim3 threadsPerBlock(16, 16); // i just did what Ta and cuda said the best to use\n    dim3 numBlocks((cols + threadsPerBlock.x - 1) / threadsPerBlock.x,\n                   (rows + threadsPerBlock.y - 1) / threadsPerBlock.y);\n    \n    matrixAddKernel1<<<numBlocks, threadsPerBlock>>>(dev_C, dev_A, dev_B, rows, cols);\n\n    // Copy output matrix from GPU buffer to host memory\n    cudaStatus = cudaMemcpy(C, dev_C, size, cudaMemcpyDeviceToHost);\n\n    return cudaStatus;\n}\n\nint main(int argc, char* argv[]) {\n\n    FILE *file_reading;\n    int numberOfTests;\n    size_t  rows, cols;\n    // Open the file in read mode\n    file_reading = fopen(argv[1], \"r\");\n    if (file_reading == NULL) {\n        printf(\"Error opening file!\\n\");\n        return 1;\n    }\n    // Read number of tests\n    fscanf(file_reading, \"%d\",&numberOfTests);\nfor(size_t i=0;i<numberOfTests;i++){\n    \n    // Read matrix dimensions\n    fscanf(file_reading, \"%zu %zu\", &rows, &cols);\n\n    // Allocate host matrices\n    double* A = (double*)malloc(sizeof(double) * rows * cols);  // Changed from size_t to double\n    double* B = (double*)malloc(sizeof(double) * rows * cols);\n    double* C = (double*)malloc(sizeof(double) * rows * cols);\n\n    // Read matrices A and B\n    for (size_t i = 0; i < rows * cols; i++) {\n        fscanf(file_reading, \"%lf\", &A[i]);\n    }\n    for (size_t i = 0; i < rows * cols; i++) {\n        fscanf(file_reading, \"%lf\", &B[i]);\n    }\n    \n \n\n    // Add matrices using CUDA\n    cudaError_t cudaStatus = addMatricesWithCuda(C, A, B, rows, cols);\n\n    // Verification\n    for (size_t i = 0; i < rows * cols; i++) {\n        assert(fabs(C[i] - A[i] - B[i]) < MAX_ERR);\n    }\n\n    printf(\"Vector addition completed successfully!\\n\");\n\n    // Write results to output file\n    FILE *file_writing;\n    file_writing= fopen(argv[2], \"w\"); // Open file for writing\n    if (file_writing == NULL) {\n        perror(\"Error opening file\");\n        return 1;\n    }\n\n\n    // Write matrix C\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j++) {\n              printf(\"%.3f \", C[i * cols + j]);    \n            fprintf(file_writing, \"%.3f \", C[i * cols + j]); // Write double with 2 decimal places\n        }\n         printf(\"\\n\");  \n        fprintf(file_writing, \"\\n\"); // New line after each row\n    }\n    fclose(file_writing);\n\n\n    // Cleanup\n    free(A);\n    free(B);\n    free(C);\n}\n    return 0;\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:09:10.392688Z","iopub.execute_input":"2025-02-17T11:09:10.393024Z","iopub.status.idle":"2025-02-17T11:09:10.399670Z","shell.execute_reply.started":"2025-02-17T11:09:10.392993Z","shell.execute_reply":"2025-02-17T11:09:10.398888Z"}},"outputs":[{"name":"stdout","text":"Overwriting kernel1.cu\n","output_type":"stream"}],"execution_count":198},{"cell_type":"code","source":"!nvcc kernel1.cu -o kernel1\n!nvprof ./kernel1 inputfile.txt outputfile_kernel1.txt","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vmzESAnuV15c","outputId":"5725348d-ad4c-4c8d-c43c-f993c9ce997d","trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:09:10.400423Z","iopub.execute_input":"2025-02-17T11:09:10.400617Z","iopub.status.idle":"2025-02-17T11:09:12.966248Z","shell.execute_reply.started":"2025-02-17T11:09:10.400599Z","shell.execute_reply":"2025-02-17T11:09:12.965410Z"}},"outputs":[{"name":"stdout","text":"==5242== NVPROF is profiling process 5242, command: ./kernel1 inputfile.txt outputfile_kernel1.txt\nVector addition completed successfully!\n7682593151.425 9307621257.798 8854249266.964 4087549386.149 3439707194.127 \n8803873489.240 1909966970.166 1397633034.193 7068590033.049 3491590656.183 \n7948104694.498 4313069925.916 4640805840.438 4960592514.210 711771544.461 \nVector addition completed successfully!\n4258394483.178 3383874166.151 \n5002761596.659 3018116653.388 \nVector addition completed successfully!\n7151195548.145 3552891609.456 2462738634.944 1605793866.303 6614305951.769 6019915126.339 \n7535842869.965 5249547090.566 537876028.792 1643638077.207 4910906587.083 3822890372.163 \n6929633903.204 5232428985.481 6466724766.609 3930741405.756 3848236662.653 3429254488.717 \n5307709439.581 5313845795.434 4157938493.647 4175912989.887 5350863888.465 4186056914.385 \n6584231625.400 7177001344.189 3692395991.829 1718159940.207 3385078105.065 4876807181.588 \n1675273462.793 4077316734.557 2172254967.665 6891091089.804 1255488010.865 4514258137.121 \n5150192358.374 2453545956.993 2898406264.713 5924765059.340 8031780631.099 4437518938.174 \n7041973180.865 5626856646.039 2136559394.513 6125776157.314 7504924846.738 8863035982.280 \nVector addition completed successfully!\n5472618452.150 6700861756.825 1463260621.822 5050485860.171 6562264214.086 \n2180099526.028 2888243051.759 6367615612.763 6329286758.001 7033569114.556 \n5429405510.809 4060552646.108 8499007157.396 4492632115.032 6386310368.497 \n3339865153.410 1854019796.952 7678216156.388 4059729476.505 7359809346.039 \n4255264060.569 2751795556.936 4840473731.776 5080877306.628 3240951007.541 \n3224176578.501 5999389017.301 1298708566.853 7079863028.401 8239924443.296 \n6465664689.178 4467780657.949 4086953115.326 3603192768.734 1216704094.892 \nVector addition completed successfully!\n3639007801.689 5935415713.825 2675050326.121 2793887395.385 6726445648.216 8468055244.285 4226230808.465 7416185574.472 3977654665.630 3209527380.045 \n4989557339.717 3821461418.679 4330809917.721 5829117885.147 6298808441.558 7973363687.905 2694148743.516 4954767660.630 4440543564.681 4483167532.951 \n4894330920.557 3727594334.974 5224653766.710 2960661878.696 7421593676.418 6020771807.796 3784627923.663 3237279161.715 1743220690.712 7578741951.207 \n2158835150.435 6319090208.618 2892333371.930 5889470852.491 7902941629.144 5079780532.390 6647054589.620 5296080945.978 3135896666.484 6965195188.323 \n6645171353.664 4166315161.758 9409254782.469 5356882340.333 5673106779.568 4275406041.548 6115305554.246 6334959950.531 5815939286.103 2405865113.356 \n5083907867.152 4479339481.234 9313413153.748 5249500377.063 3256985933.155 6664621401.984 3802416404.808 2307426073.236 3102326883.744 4185231943.167 \n5182884742.395 8115873105.219 2448485311.129 2566637685.153 6657898248.850 6614536807.590 4519575511.160 454043159.765 8497162700.206 3966000440.076 \n6959412295.624 1937660083.021 4652299936.033 4291000326.662 4355564149.889 5025664990.960 3556049284.927 8186966032.738 6465618807.097 3780555014.016 \n2475697028.855 5943949122.683 4304446141.010 5841945069.448 8175511786.183 4155457906.136 5963757411.002 4923498312.905 2449569281.521 5611260896.196 \n==5242== Profiling application: ./kernel1 inputfile.txt outputfile_kernel1.txt\n==5242== Profiling result:\n            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n GPU activities:   42.59%  10.304us         5  2.0600us  1.7600us  2.6880us  matrixAddKernel1(double*, double*, double*, unsigned long, unsigned long)\n                   35.19%  8.5120us         5  1.7020us  1.4080us  1.9840us  [CUDA memcpy DtoH]\n                   22.22%  5.3760us        10     537ns     480ns     736ns  [CUDA memcpy HtoD]\n      API calls:   99.22%  84.923ms        15  5.6615ms  2.9710us  84.837ms  cudaMalloc\n                    0.30%  259.98us         5  51.996us  11.324us  201.01us  cudaLaunchKernel\n                    0.25%  209.97us        15  13.997us  6.0890us  33.761us  cudaMemcpy\n                    0.20%  172.71us       114  1.5140us     134ns  66.987us  cuDeviceGetAttribute\n                    0.02%  16.023us         1  16.023us  16.023us  16.023us  cuDeviceGetName\n                    0.01%  7.2960us         1  7.2960us  7.2960us  7.2960us  cuDeviceGetPCIBusId\n                    0.00%  2.5040us         3     834ns     230ns  1.8680us  cuDeviceGetCount\n                    0.00%     835ns         2     417ns     162ns     673ns  cuDeviceGet\n                    0.00%     545ns         1     545ns     545ns     545ns  cuDeviceTotalMem\n                    0.00%     308ns         1     308ns     308ns     308ns  cuModuleGetLoadingMode\n                    0.00%     217ns         1     217ns     217ns     217ns  cuDeviceGetUuid\n","output_type":"stream"}],"execution_count":199},{"cell_type":"markdown","source":"# kernel2: each thread produces one output matrix row\n","metadata":{}},{"cell_type":"code","source":"%%writefile kernel2.cu   \n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <assert.h>\n#include \"cuda_runtime.h\"\n#include \"device_launch_parameters.h\"\n#include <fstream>\n#include <iostream>\n#include <sstream>\n#define MAX_ERR 1e-6\n__global__ void matrixAddKernel1(double* C, double* A, double* B, size_t rows, size_t cols) {\n    size_t row = blockIdx.x * blockDim.x + threadIdx.x;\n    if (row < rows) {\n        for(size_t col =0 ; col < cols; col++){\n              size_t idx = row * cols + col;\n            C[idx] = A[idx] + B[idx];\n        }\n    }\n}\n\ncudaError_t addMatricesWithCuda(double* C, double* A, double* B, size_t rows, size_t cols) {\n    double* dev_A = nullptr;\n    double* dev_B = nullptr;\n    double* dev_C = nullptr;\n    cudaError_t cudaStatus;\n\n    // Allocate GPU buffers\n    size_t size = rows * cols * sizeof(double);  // Changed from size_t to double\n    \n    cudaStatus = cudaMalloc((void**)&dev_C, size);\n    \n    cudaStatus = cudaMalloc((void**)&dev_A, size);\n\n    cudaStatus = cudaMalloc((void**)&dev_B, size);\n\n    // Copy input matrices from host memory to GPU buffers\n    cudaStatus = cudaMemcpy(dev_A, A, size, cudaMemcpyHostToDevice);    \n    cudaStatus = cudaMemcpy(dev_B, B, size, cudaMemcpyHostToDevice);\n\n    // Launch kernel\n    dim3 threadsPerBlock(16, 16); // i just did what Ta and cuda said the best to use\n    dim3 numBlocks((cols + threadsPerBlock.x - 1) / threadsPerBlock.x,\n                   (rows + threadsPerBlock.y - 1) / threadsPerBlock.y);\n    \n    matrixAddKernel1<<<numBlocks, threadsPerBlock>>>(dev_C, dev_A, dev_B, rows, cols);\n\n    // Copy output matrix from GPU buffer to host memory\n    cudaStatus = cudaMemcpy(C, dev_C, size, cudaMemcpyDeviceToHost);\n\n    return cudaStatus;\n}\n\nint main(int argc, char* argv[]) {\n\n    FILE *file_reading;\n    int numberOfTests;\n    size_t  rows, cols;\n    // Open the file in read mode\n    file_reading = fopen(argv[1], \"r\");\n    if (file_reading == NULL) {\n        printf(\"Error opening file!\\n\");\n        return 1;\n    }\n    // Read number of tests\n    fscanf(file_reading, \"%d\",&numberOfTests);\nfor(size_t i=0;i<numberOfTests;i++){\n    \n    // Read matrix dimensions\n    fscanf(file_reading, \"%zu %zu\", &rows, &cols);\n\n    // Allocate host matrices\n    double* A = (double*)malloc(sizeof(double) * rows * cols);  // Changed from size_t to double\n    double* B = (double*)malloc(sizeof(double) * rows * cols);\n    double* C = (double*)malloc(sizeof(double) * rows * cols);\n\n    // Read matrices A and B\n    for (size_t i = 0; i < rows * cols; i++) {\n        fscanf(file_reading, \"%lf\", &A[i]);\n    }\n    for (size_t i = 0; i < rows * cols; i++) {\n        fscanf(file_reading, \"%lf\", &B[i]);\n    }\n    \n \n\n    // Add matrices using CUDA\n    cudaError_t cudaStatus = addMatricesWithCuda(C, A, B, rows, cols);\n\n    // Verification\n    for (size_t i = 0; i < rows * cols; i++) {\n        assert(fabs(C[i] - A[i] - B[i]) < MAX_ERR);\n    }\n\n    printf(\"Vector addition completed successfully!\\n\");\n\n    // Write results to output file\n    FILE *file_writing;\n    file_writing= fopen(argv[2], \"w\"); // Open file for writing\n    if (file_writing == NULL) {\n        perror(\"Error opening file\");\n        return 1;\n    }\n\n\n    // Write matrix C\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j++) {\n              printf(\"%.3f \", C[i * cols + j]);    \n            fprintf(file_writing, \"%.3f \", C[i * cols + j]); // Write double with 2 decimal places\n        }\n         printf(\"\\n\");  \n        fprintf(file_writing, \"\\n\"); // New line after each row\n    }\n    fclose(file_writing);\n\n\n    // Cleanup\n    free(A);\n    free(B);\n    free(C);\n}\n    return 0;\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:09:12.967270Z","iopub.execute_input":"2025-02-17T11:09:12.967571Z","iopub.status.idle":"2025-02-17T11:09:12.973841Z","shell.execute_reply.started":"2025-02-17T11:09:12.967548Z","shell.execute_reply":"2025-02-17T11:09:12.972954Z"}},"outputs":[{"name":"stdout","text":"Overwriting kernel2.cu\n","output_type":"stream"}],"execution_count":200},{"cell_type":"code","source":"!nvcc kernel2.cu -o kernel2\n!nvprof ./kernel2 inputfile.txt outputfile_kernel2.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:09:12.974691Z","iopub.execute_input":"2025-02-17T11:09:12.974990Z","iopub.status.idle":"2025-02-17T11:09:15.514352Z","shell.execute_reply.started":"2025-02-17T11:09:12.974968Z","shell.execute_reply":"2025-02-17T11:09:15.513478Z"}},"outputs":[{"name":"stdout","text":"==5286== NVPROF is profiling process 5286, command: ./kernel2 inputfile.txt outputfile_kernel2.txt\nVector addition completed successfully!\n7682593151.425 9307621257.798 8854249266.964 4087549386.149 3439707194.127 \n8803873489.240 1909966970.166 1397633034.193 7068590033.049 3491590656.183 \n7948104694.498 4313069925.916 4640805840.438 4960592514.210 711771544.461 \nVector addition completed successfully!\n4258394483.178 3383874166.151 \n5002761596.659 3018116653.388 \nVector addition completed successfully!\n7151195548.145 3552891609.456 2462738634.944 1605793866.303 6614305951.769 6019915126.339 \n7535842869.965 5249547090.566 537876028.792 1643638077.207 4910906587.083 3822890372.163 \n6929633903.204 5232428985.481 6466724766.609 3930741405.756 3848236662.653 3429254488.717 \n5307709439.581 5313845795.434 4157938493.647 4175912989.887 5350863888.465 4186056914.385 \n6584231625.400 7177001344.189 3692395991.829 1718159940.207 3385078105.065 4876807181.588 \n1675273462.793 4077316734.557 2172254967.665 6891091089.804 1255488010.865 4514258137.121 \n5150192358.374 2453545956.993 2898406264.713 5924765059.340 8031780631.099 4437518938.174 \n7041973180.865 5626856646.039 2136559394.513 6125776157.314 7504924846.738 8863035982.280 \nVector addition completed successfully!\n5472618452.150 6700861756.825 1463260621.822 5050485860.171 6562264214.086 \n2180099526.028 2888243051.759 6367615612.763 6329286758.001 7033569114.556 \n5429405510.809 4060552646.108 8499007157.396 4492632115.032 6386310368.497 \n3339865153.410 1854019796.952 7678216156.388 4059729476.505 7359809346.039 \n4255264060.569 2751795556.936 4840473731.776 5080877306.628 3240951007.541 \n3224176578.501 5999389017.301 1298708566.853 7079863028.401 8239924443.296 \n6465664689.178 4467780657.949 4086953115.326 3603192768.734 1216704094.892 \nVector addition completed successfully!\n3639007801.689 5935415713.825 2675050326.121 2793887395.385 6726445648.216 8468055244.285 4226230808.465 7416185574.472 3977654665.630 3209527380.045 \n4989557339.717 3821461418.679 4330809917.721 5829117885.147 6298808441.558 7973363687.905 2694148743.516 4954767660.630 4440543564.681 4483167532.951 \n4894330920.557 3727594334.974 5224653766.710 2960661878.696 7421593676.418 6020771807.796 3784627923.663 3237279161.715 1743220690.712 7578741951.207 \n2158835150.435 6319090208.618 2892333371.930 5889470852.491 7902941629.144 5079780532.390 6647054589.620 5296080945.978 3135896666.484 6965195188.323 \n6645171353.664 4166315161.758 9409254782.469 5356882340.333 5673106779.568 4275406041.548 6115305554.246 6334959950.531 5815939286.103 2405865113.356 \n5083907867.152 4479339481.234 9313413153.748 5249500377.063 3256985933.155 6664621401.984 3802416404.808 2307426073.236 3102326883.744 4185231943.167 \n5182884742.395 8115873105.219 2448485311.129 2566637685.153 6657898248.850 6614536807.590 4519575511.160 454043159.765 8497162700.206 3966000440.076 \n6959412295.624 1937660083.021 4652299936.033 4291000326.662 4355564149.889 5025664990.960 3556049284.927 8186966032.738 6465618807.097 3780555014.016 \n2475697028.855 5943949122.683 4304446141.010 5841945069.448 8175511786.183 4155457906.136 5963757411.002 4923498312.905 2449569281.521 5611260896.196 \n==5286== Profiling application: ./kernel2 inputfile.txt outputfile_kernel2.txt\n==5286== Profiling result:\n            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n GPU activities:   54.22%  16.640us         5  3.3280us  2.3360us  4.3200us  matrixAddKernel1(double*, double*, double*, unsigned long, unsigned long)\n                   27.84%  8.5440us         5  1.7080us  1.4080us  1.9840us  [CUDA memcpy DtoH]\n                   17.94%  5.5040us        10     550ns     480ns     736ns  [CUDA memcpy HtoD]\n      API calls:   99.19%  87.105ms        15  5.8070ms  2.8950us  87.011ms  cudaMalloc\n                    0.29%  255.27us         5  51.054us  11.297us  200.38us  cudaLaunchKernel\n                    0.26%  224.67us        15  14.978us  6.3650us  32.428us  cudaMemcpy\n                    0.23%  199.92us       114  1.7530us     128ns  91.978us  cuDeviceGetAttribute\n                    0.02%  18.705us         1  18.705us  18.705us  18.705us  cuDeviceGetName\n                    0.01%  7.3530us         1  7.3530us  7.3530us  7.3530us  cuDeviceGetPCIBusId\n                    0.00%  2.0260us         3     675ns     195ns  1.5180us  cuDeviceGetCount\n                    0.00%     855ns         2     427ns     220ns     635ns  cuDeviceGet\n                    0.00%     780ns         1     780ns     780ns     780ns  cuDeviceTotalMem\n                    0.00%     397ns         1     397ns     397ns     397ns  cuModuleGetLoadingMode\n                    0.00%     292ns         1     292ns     292ns     292ns  cuDeviceGetUuid\n","output_type":"stream"}],"execution_count":201},{"cell_type":"markdown","source":"# kernel3: each thread produces one output matrix col\n","metadata":{}},{"cell_type":"code","source":"%%writefile kernel3.cu   \n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <assert.h>\n#include \"cuda_runtime.h\"\n#include \"device_launch_parameters.h\"\n#include <fstream>\n#include <iostream>\n#include <sstream>\n#define MAX_ERR 1e-6\n__global__ void matrixAddKernel1(double* C, double* A, double* B, size_t rows, size_t cols) {\n    size_t col = blockIdx.x * blockDim.x + threadIdx.x;\n    if ( col < cols) {\n        for(size_t row = 0; row< rows ; row++){\n            size_t idx = row * cols + col;\n            C[idx] = A[idx] + B[idx];\n        }\n   \n    }\n}\n\ncudaError_t addMatricesWithCuda(double* C, double* A, double* B, size_t rows, size_t cols) {\n    double* dev_A = nullptr;\n    double* dev_B = nullptr;\n    double* dev_C = nullptr;\n    cudaError_t cudaStatus;\n\n    // Allocate GPU buffers\n    size_t size = rows * cols * sizeof(double);  // Changed from size_t to double\n    \n    cudaStatus = cudaMalloc((void**)&dev_C, size);\n    \n    cudaStatus = cudaMalloc((void**)&dev_A, size);\n\n    cudaStatus = cudaMalloc((void**)&dev_B, size);\n\n    // Copy input matrices from host memory to GPU buffers\n    cudaStatus = cudaMemcpy(dev_A, A, size, cudaMemcpyHostToDevice);    \n    cudaStatus = cudaMemcpy(dev_B, B, size, cudaMemcpyHostToDevice);\n\n    // Launch kernel\n    dim3 threadsPerBlock(16, 16); // i just did what Ta and cuda said the best to use\n    dim3 numBlocks((cols + threadsPerBlock.x - 1) / threadsPerBlock.x,\n                   (rows + threadsPerBlock.y - 1) / threadsPerBlock.y);\n    \n    matrixAddKernel1<<<numBlocks, threadsPerBlock>>>(dev_C, dev_A, dev_B, rows, cols);\n\n    // Copy output matrix from GPU buffer to host memory\n    cudaStatus = cudaMemcpy(C, dev_C, size, cudaMemcpyDeviceToHost);\n\n    return cudaStatus;\n}\n\nint main(int argc, char* argv[]) {\n\n    FILE *file_reading;\n    int numberOfTests;\n    size_t  rows, cols;\n    // Open the file in read mode\n    file_reading = fopen(argv[1], \"r\");\n    if (file_reading == NULL) {\n        printf(\"Error opening file!\\n\");\n        return 1;\n    }\n    // Read number of tests\n    fscanf(file_reading, \"%d\",&numberOfTests);\nfor(size_t i=0;i<numberOfTests;i++){\n    \n    // Read matrix dimensions\n    fscanf(file_reading, \"%zu %zu\", &rows, &cols);\n\n    // Allocate host matrices\n    double* A = (double*)malloc(sizeof(double) * rows * cols);  // Changed from size_t to double\n    double* B = (double*)malloc(sizeof(double) * rows * cols);\n    double* C = (double*)malloc(sizeof(double) * rows * cols);\n\n    // Read matrices A and B\n    for (size_t i = 0; i < rows * cols; i++) {\n        fscanf(file_reading, \"%lf\", &A[i]);\n    }\n    for (size_t i = 0; i < rows * cols; i++) {\n        fscanf(file_reading, \"%lf\", &B[i]);\n    }\n    \n \n\n    // Add matrices using CUDA\n    cudaError_t cudaStatus = addMatricesWithCuda(C, A, B, rows, cols);\n\n    // Verification\n    for (size_t i = 0; i < rows * cols; i++) {\n        assert(fabs(C[i] - A[i] - B[i]) < MAX_ERR);\n    }\n\n    printf(\"Vector addition completed successfully!\\n\");\n\n    // Write results to output file\n    FILE *file_writing;\n    file_writing= fopen(argv[2], \"w\"); // Open file for writing\n    if (file_writing == NULL) {\n        perror(\"Error opening file\");\n        return 1;\n    }\n\n\n    // Write matrix C\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j++) {\n            printf(\"%.3f \", C[i * cols + j]);    \n            fprintf(file_writing, \"%.3f \", C[i * cols + j]); // Write double with 2 decimal places\n        }\n        printf(\"\\n\");  \n        fprintf(file_writing, \"\\n\"); // New line after each row\n    }\n    fclose(file_writing);\n\n\n    // Cleanup\n    free(A);\n    free(B);\n    free(C);\n}\n    return 0;\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:09:15.516312Z","iopub.execute_input":"2025-02-17T11:09:15.516579Z","iopub.status.idle":"2025-02-17T11:09:15.522944Z","shell.execute_reply.started":"2025-02-17T11:09:15.516556Z","shell.execute_reply":"2025-02-17T11:09:15.521897Z"}},"outputs":[{"name":"stdout","text":"Overwriting kernel3.cu\n","output_type":"stream"}],"execution_count":202},{"cell_type":"code","source":"!nvcc kernel3.cu -o kernel3\n!nvprof ./kernel3 inputfile.txt outputfile_kernel3.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:09:15.524009Z","iopub.execute_input":"2025-02-17T11:09:15.524342Z","iopub.status.idle":"2025-02-17T11:09:18.084042Z","shell.execute_reply.started":"2025-02-17T11:09:15.524310Z","shell.execute_reply":"2025-02-17T11:09:18.083151Z"}},"outputs":[{"name":"stdout","text":"==5330== NVPROF is profiling process 5330, command: ./kernel3 inputfile.txt outputfile_kernel3.txt\nVector addition completed successfully!\n7682593151.425 9307621257.798 8854249266.964 4087549386.149 3439707194.127 \n8803873489.240 1909966970.166 1397633034.193 7068590033.049 3491590656.183 \n7948104694.498 4313069925.916 4640805840.438 4960592514.210 711771544.461 \nVector addition completed successfully!\n4258394483.178 3383874166.151 \n5002761596.659 3018116653.388 \nVector addition completed successfully!\n7151195548.145 3552891609.456 2462738634.944 1605793866.303 6614305951.769 6019915126.339 \n7535842869.965 5249547090.566 537876028.792 1643638077.207 4910906587.083 3822890372.163 \n6929633903.204 5232428985.481 6466724766.609 3930741405.756 3848236662.653 3429254488.717 \n5307709439.581 5313845795.434 4157938493.647 4175912989.887 5350863888.465 4186056914.385 \n6584231625.400 7177001344.189 3692395991.829 1718159940.207 3385078105.065 4876807181.588 \n1675273462.793 4077316734.557 2172254967.665 6891091089.804 1255488010.865 4514258137.121 \n5150192358.374 2453545956.993 2898406264.713 5924765059.340 8031780631.099 4437518938.174 \n7041973180.865 5626856646.039 2136559394.513 6125776157.314 7504924846.738 8863035982.280 \nVector addition completed successfully!\n5472618452.150 6700861756.825 1463260621.822 5050485860.171 6562264214.086 \n2180099526.028 2888243051.759 6367615612.763 6329286758.001 7033569114.556 \n5429405510.809 4060552646.108 8499007157.396 4492632115.032 6386310368.497 \n3339865153.410 1854019796.952 7678216156.388 4059729476.505 7359809346.039 \n4255264060.569 2751795556.936 4840473731.776 5080877306.628 3240951007.541 \n3224176578.501 5999389017.301 1298708566.853 7079863028.401 8239924443.296 \n6465664689.178 4467780657.949 4086953115.326 3603192768.734 1216704094.892 \nVector addition completed successfully!\n3639007801.689 5935415713.825 2675050326.121 2793887395.385 6726445648.216 8468055244.285 4226230808.465 7416185574.472 3977654665.630 3209527380.045 \n4989557339.717 3821461418.679 4330809917.721 5829117885.147 6298808441.558 7973363687.905 2694148743.516 4954767660.630 4440543564.681 4483167532.951 \n4894330920.557 3727594334.974 5224653766.710 2960661878.696 7421593676.418 6020771807.796 3784627923.663 3237279161.715 1743220690.712 7578741951.207 \n2158835150.435 6319090208.618 2892333371.930 5889470852.491 7902941629.144 5079780532.390 6647054589.620 5296080945.978 3135896666.484 6965195188.323 \n6645171353.664 4166315161.758 9409254782.469 5356882340.333 5673106779.568 4275406041.548 6115305554.246 6334959950.531 5815939286.103 2405865113.356 \n5083907867.152 4479339481.234 9313413153.748 5249500377.063 3256985933.155 6664621401.984 3802416404.808 2307426073.236 3102326883.744 4185231943.167 \n5182884742.395 8115873105.219 2448485311.129 2566637685.153 6657898248.850 6614536807.590 4519575511.160 454043159.765 8497162700.206 3966000440.076 \n6959412295.624 1937660083.021 4652299936.033 4291000326.662 4355564149.889 5025664990.960 3556049284.927 8186966032.738 6465618807.097 3780555014.016 \n2475697028.855 5943949122.683 4304446141.010 5841945069.448 8175511786.183 4155457906.136 5963757411.002 4923498312.905 2449569281.521 5611260896.196 \n==5330== Profiling application: ./kernel3 inputfile.txt outputfile_kernel3.txt\n==5330== Profiling result:\n            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n GPU activities:   55.15%  17.120us         5  3.4240us  2.3680us  3.9680us  matrixAddKernel1(double*, double*, double*, unsigned long, unsigned long)\n                   27.42%  8.5120us         5  1.7020us  1.4080us  1.9840us  [CUDA memcpy DtoH]\n                   17.42%  5.4080us        10     540ns     480ns     736ns  [CUDA memcpy HtoD]\n      API calls:   98.98%  85.867ms        15  5.7245ms  3.2710us  85.774ms  cudaMalloc\n                    0.33%  290.44us         5  58.087us  12.286us  224.55us  cudaLaunchKernel\n                    0.32%  278.50us        15  18.566us  6.5450us  48.661us  cudaMemcpy\n                    0.29%  255.08us       114  2.2370us     168ns  103.79us  cuDeviceGetAttribute\n                    0.05%  41.460us         1  41.460us  41.460us  41.460us  cuDeviceGetName\n                    0.01%  9.9850us         1  9.9850us  9.9850us  9.9850us  cuDeviceGetPCIBusId\n                    0.00%  2.6130us         3     871ns     229ns  1.6990us  cuDeviceGetCount\n                    0.00%  2.3930us         2  1.1960us     488ns  1.9050us  cuDeviceGet\n                    0.00%     792ns         1     792ns     792ns     792ns  cuDeviceTotalMem\n                    0.00%     457ns         1     457ns     457ns     457ns  cuDeviceGetUuid\n                    0.00%     455ns         1     455ns     455ns     455ns  cuModuleGetLoadingMode\n","output_type":"stream"}],"execution_count":203}]}
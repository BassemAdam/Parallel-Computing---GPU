{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aac2TowwLTKb"
      },
      "source": [
        "### **Python in the loop**\n",
        "\n",
        "As we are kind of fed-up with the silly huge C portions of code that we essentially need to write in order to produce a fully-functioning cuda program, let's introduce how we can add python in the loop, so that we get the benefit of its endless facilities, and conveniently carry out operations as: reading/writing folders, files, images, audio files, ... etc.\n",
        "\n",
        "Let's first divide the code we write into 3 parts:\n",
        "\n",
        "\n",
        "*   The core kernel code\n",
        "*   The data handling wrapper (memory allocations, data transfer and kernel invocation)\n",
        "*   Other program code concerned with inputs and outputs.\n",
        "\n",
        "We'll now show how keep out kernel and wrapper C code (parts 1&2), compile it into a dynamic library, then link this library to the python program."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFtsTcDPOyn9",
        "outputId": "b6150f86-4262-47b4-8153-976343a166bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-0o5j4oqy\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-0o5j4oqy\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 28f872a2f99a1b201bcd0db14fdbc5a496b9bfd7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.2.1-py3-none-any.whl size=10742 sha256=fdb30b442a03a2b978d94f242f4f3839c3b517111d4c5bcc31496f40b5aacbba\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_dx40vwh/wheels/ef/1d/c6/f7e47f1aa1bc9d05c4120d94f90a79cf28603ef343b0dd43ff\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n",
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpz99eu91i\".\n"
          ]
        }
      ],
      "source": [
        "# Setup cuda environment\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKekzMmyXeB_",
        "outputId": "5971c836-2351-460b-ce95-c7a548e8879f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing sumArrayGPU.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile sumArrayGPU.cu\n",
        "\n",
        "// CUDA kernel function\n",
        "__global__ void my_cuda_kernel(int *input, int *output, int size) {\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (tid < size) {\n",
        "        output[tid] = input[tid] * 2;  //# Example: Double each element\n",
        "    }\n",
        "}\n",
        "\n",
        "// Wrapper function to call the CUDA kernel\n",
        "extern \"C\" void my_cuda_function(int *input, int *output, int size) {\n",
        "    // Allocate device memory\n",
        "    int *d_input, *d_output;\n",
        "    cudaMalloc((void**)&d_input, size * sizeof(int));\n",
        "    cudaMalloc((void**)&d_output, size * sizeof(int));\n",
        "\n",
        "    // Copy input data to device\n",
        "    cudaMemcpy(d_input, input, size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch CUDA kernel\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (size + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    my_cuda_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_input, d_output, size);\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(output, d_output, size * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDUg-yWsX3cJ"
      },
      "outputs": [],
      "source": [
        "# Compile the cuda code and produce a shared library to get linked to the python main program\n",
        "!nvcc -arch=sm_75 -o sumArrayGPU.so -shared -Xcompiler -fPIC sumArrayGPU.cu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRbo0I-yX-Mb",
        "outputId": "e8fd9194-f976-4067-d69d-681d73ee77a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: [2, 4, 6, 8]\n"
          ]
        }
      ],
      "source": [
        "# Python function calling the compiled C++/CUDA function\n",
        "\n",
        "# ctypes in python bridges the gap between python dynamic data types and c static ones.\n",
        "import ctypes\n",
        "\n",
        "# Load the CUDA library\n",
        "cuda_lib = ctypes.CDLL('./sumArrayGPU.so')  # Update with the correct path\n",
        "\n",
        "# Define the function prototype\n",
        "cuda_lib.my_cuda_function.argtypes = [ctypes.POINTER(ctypes.c_int), ctypes.POINTER(ctypes.c_int), ctypes.c_int]\n",
        "cuda_lib.my_cuda_function.restype = None\n",
        "\n",
        "# Prepare data\n",
        "input_data = [1, 2, 3, 4]\n",
        "output_data = [0, 0, 0, 0]\n",
        "size = len(input_data)\n",
        "\n",
        "# Convert Python lists to ctypes arrays\n",
        "input_array = (ctypes.c_int * size)(*input_data)\n",
        "output_array = (ctypes.c_int * size)(*output_data)\n",
        "\n",
        "# Call the CUDA function\n",
        "cuda_lib.my_cuda_function(input_array, output_array, size)\n",
        "\n",
        "# Print the result\n",
        "result = list(output_array)\n",
        "print(\"Result:\", result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Python function calling the compiled C++/CUDA function\n",
        "\n",
        "# ctypes in python bridges the gap between python dynamic data types and c static ones.\n",
        "import ctypes\n",
        "import numpy as np\n",
        "\n",
        "# Load the CUDA library\n",
        "cuda_lib = ctypes.CDLL('./sumArrayGPU.so')  # Update with the correct path\n",
        "\n",
        "# Define the function prototype\n",
        "cuda_lib.my_cuda_function.argtypes = [ctypes.POINTER(ctypes.c_int), ctypes.POINTER(ctypes.c_int), ctypes.c_int]\n",
        "cuda_lib.my_cuda_function.restype = None\n",
        "\n",
        "# Prepare data\n",
        "input_data = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
        "output_data = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
        "size = len(input_data.flatten())\n",
        "\n",
        "# Convert Python lists to ctypes arrays\n",
        "input_array = (ctypes.c_int * size)(*input_data.flatten())\n",
        "output_array = (ctypes.c_int * size)(*output_data.flatten())\n",
        "\n",
        "# Call the CUDA function\n",
        "cuda_lib.my_cuda_function(input_array, output_array, size)\n",
        "\n",
        "# Print the result\n",
        "result = np.array(list(output_array)).reshape(2, 4)\n",
        "print(\"Result:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--5L76cap_hi",
        "outputId": "a1d9a10c-d273-495a-b56d-8a5c28b9c20e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: [[ 2  4  6  8]\n",
            " [10 12 14 16]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "mat = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
        "\n",
        "print(mat.flatten())\n",
        "\n",
        "volume = np.array([[[1,1,1],\n",
        "                    [2,2,2],],\n",
        "                  [[3,3,3],\n",
        "                   [4,4,4],],\n",
        "                  [[5,5,5],\n",
        "                   [6,6,6],]\n",
        "                   ])\n",
        "\n",
        "print(volume.flatten())\n",
        "\n",
        "print(mat.flatten().reshape((3,3)))\n",
        "print()\n",
        "print(volume.flatten().reshape((3,2,3)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgjnRcZrq-RP",
        "outputId": "1ae2b347-80eb-4b03-e251-6ca3c9fb6526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3 4 5 6 7 8 9]\n",
            "[1 1 1 2 2 2 3 3 3 4 4 4 5 5 5 6 6 6]\n",
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n",
            "\n",
            "[[[1 1 1]\n",
            "  [2 2 2]]\n",
            "\n",
            " [[3 3 3]\n",
            "  [4 4 4]]\n",
            "\n",
            " [[5 5 5]\n",
            "  [6 6 6]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89sBrBJ-OzrL"
      },
      "source": [
        "### **Resources**\n",
        "\n",
        "*   https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n",
        "*   https://developer.nvidia.com/blog/how-overlap-data-transfers-cuda-cc/#overlapping_kernel_execution_and_data_transfers\n",
        "*   https://developer.nvidia.com/blog/gpu-pro-tip-cuda-7-streams-simplify-concurrency/\n",
        "*   https://vitalitylearning.medium.com/using-c-c-and-cuda-functions-as-regular-python-functions-716f01f7ca22\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
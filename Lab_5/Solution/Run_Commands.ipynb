{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements for 3D RGB Image Convolution\n",
    "\n",
    "#### A) CUDA Implementation\n",
    "\n",
    "Implement a CUDA program for 3D convolution on RGB images with three kernel variations:\n",
    "\n",
    "1. **Kernel 1:** Basic implementation (no tiling)\n",
    "2. **Kernel 2:** Tiling with block size matching input tile size\n",
    "3. **Kernel 3:** Tiling with block size matching output tile size\n",
    "\n",
    "**Program Structure:**\n",
    "```\n",
    "./program <input_folder_path> <output_folder_path> <batch_size> <mask_file> [stride]\n",
    "```\n",
    "\n",
    "**Technical Requirements:**\n",
    "- Add appropriate padding to maintain output dimensions when stride = 1\n",
    "- Process multiple images in batches (batch size provided as argument)\n",
    "- Apply the mask to all three RGB channels\n",
    "- (BONUS) Support variable stride values\n",
    "\n",
    "**Mask File Format:**\n",
    "- First line: dimension n (square mask)\n",
    "- Next n lines: mask values (one row per line)\n",
    "\n",
    "#### B) PyTorch Implementation\n",
    "\n",
    "Create a Python equivalent using PyTorch's built-in convolution functions.\n",
    "\n",
    "#### C) Performance Analysis\n",
    "\n",
    "Conduct thorough performance profiling:\n",
    "\n",
    "1. Compare execution times across implementations\n",
    "2. Analyze the impact of declaring the mask as constant memory\n",
    "3. Present results in well-organized tables\n",
    "4. Prepare a comprehensive report explaining:\n",
    "   - Performance comparisons between implementations\n",
    "   - Analysis of memory optimizations\n",
    "   - Observations about constant memory impact\n",
    "   - Factors affecting convolution performance\n",
    "\n",
    "#### Submission\n",
    "\n",
    "Submit a complete report with experimental results, analysis, and code implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_run_kernel(kernel_number, input_folder, output_folder, batch_size, mask_file, stride=1, analytics=False):\n",
    "    \"\"\"\n",
    "    Compile and run a CUDA kernel for 3D RGB image convolution.\n",
    "    \n",
    "    Args:\n",
    "        kernel_number (int): Kernel implementation to use (1, 2, or 3)\n",
    "        input_folder (str): Path to the folder containing input images\n",
    "        output_folder (str): Path to the folder where processed images will be saved\n",
    "        batch_size (int): Number of images to process in a batch\n",
    "        mask_file (str): Path to the convolution mask file\n",
    "        stride (int, optional): Stride value for convolution. Defaults to 1.\n",
    "        analytics (bool, optional): Whether to run with NVIDIA profiler. Defaults to False.\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the output folder\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import time\n",
    "    \n",
    "    # Get current working directory\n",
    "    cwd = os.getcwd()\n",
    "    print(f\"Current working directory: {cwd}\")\n",
    "    \n",
    "    # Create paths\n",
    "    kernel_src = os.path.join(cwd, f\"cuda_kernels/kernel{kernel_number}.cu\")\n",
    "    kernel_exe = os.path.join(cwd, f\"cuda_kernels/bin/kernel{kernel_number}.exe\")\n",
    "    \n",
    "    # Ensure input and mask file paths are absolute\n",
    "    input_folder_path = os.path.abspath(input_folder)\n",
    "    output_folder_path = os.path.abspath(output_folder)\n",
    "    mask_file_path = os.path.abspath(mask_file)\n",
    "    \n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder_path, exist_ok=True)\n",
    "    \n",
    "    # Create bin directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(kernel_exe), exist_ok=True)\n",
    "    \n",
    "    # Compile with appropriate flags\n",
    "    print(f\"Compiling kernel {kernel_number}...\")\n",
    "    !nvcc \"{kernel_src}\" -o \"{kernel_exe}\" --use_fast_math -O3\n",
    "    \n",
    "    # Print configuration details\n",
    "    kernel_types = {\n",
    "        1: \"Basic implementation (no tiling)\",\n",
    "        2: \"Tiling with block size matching input tile size\",\n",
    "        3: \"Tiling with block size matching output tile size\"\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nRunning Kernel {kernel_number}: {kernel_types.get(kernel_number, 'Unknown')}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(f\"Stride: {stride}\")\n",
    "    print(f\"Input folder: {input_folder_path}\")\n",
    "    print(f\"Output folder: {output_folder_path}\")\n",
    "    print(f\"Mask file: {mask_file_path}\")\n",
    "    \n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Run with analytics if requested, otherwise run normally\n",
    "    if analytics:\n",
    "        # Create analytics_Bin directory if it doesn't exist\n",
    "        analytics_dir = os.path.join(cwd, \"analytics_Bin\")\n",
    "        os.makedirs(analytics_dir, exist_ok=True)\n",
    "        \n",
    "        # Set profile output path inside analytics_Bin folder\n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        profile_output = os.path.join(analytics_dir, f\"profile_k{kernel_number}_b{batch_size}_s{stride}_{timestamp}\")\n",
    "        \n",
    "        # Run with nsys profiling\n",
    "        !nsys profile --sample=none --trace=cuda --force-overwrite=true --stats=true --output=\"{profile_output}\" \"{kernel_exe}\" \"{input_folder_path}\" \"{output_folder_path}\" \"{batch_size}\" \"{mask_file_path}\" \"{stride}\"\n",
    "        print(f\"Analytics data saved to {profile_output}\")\n",
    "    else:\n",
    "        # Run normally\n",
    "        !\"{kernel_exe}\" \"{input_folder_path}\" \"{output_folder_path}\" \"{batch_size}\" \"{mask_file_path}\" \"{stride}\"\n",
    "    \n",
    "    # End timing\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"\\nExecution completed in {execution_time:.4f} seconds\")\n",
    "    return output_folder_path\n",
    "\n",
    "# Example usage:\n",
    "# output = compile_and_run_kernel(1, \"input_images\", \"output_images\", 16, \"masks/mask5x5.txt\")\n",
    "# output = compile_and_run_kernel(2, \"input_images\", \"output_images\", 16, \"masks/mask5x5.txt\", stride=2, analytics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "def compare_image_outputs(reference_folder, output_folder, tolerance=1e-5, verbose=False):\n",
    "    \"\"\"\n",
    "    Compare the output RGB images to check if they match within tolerance.\n",
    "    \n",
    "    Parameters:\n",
    "    - reference_folder: Path to folder containing reference/expected RGB images\n",
    "    - output_folder: Path to folder containing output RGB images from your implementation\n",
    "    - tolerance: Maximum allowed difference between corresponding pixel values\n",
    "    - verbose: Whether to print details about the comparison\n",
    "    \n",
    "    Returns:\n",
    "    - True if images match within tolerance, False otherwise\n",
    "    \"\"\"\n",
    "   # Ensure paths are Path objects\n",
    "    ref_path = Path(reference_folder)\n",
    "    out_path = Path(output_folder)\n",
    "    \n",
    "    # Get all image files in reference folder (supporting multiple formats)\n",
    "    ref_files = []\n",
    "    for ext in ['*.png', '*.jpg', '*.jpeg']:\n",
    "        ref_files.extend(ref_path.glob(ext))\n",
    "    ref_files = sorted([f for f in ref_files if f.is_file()])\n",
    "    \n",
    "    if not ref_files:\n",
    "        print(f\"❌ FAIL: No reference images found in {reference_folder}\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"Found {len(ref_files)} reference images to compare.\")\n",
    "    \n",
    "    # Track overall results\n",
    "    all_match = True\n",
    "    total_images = 0\n",
    "    matched_images = 0\n",
    "    \n",
    "    # Statistics collection\n",
    "    max_differences = []\n",
    "    mean_differences = []\n",
    "    \n",
    "    for ref_file in ref_files:\n",
    "        # Construct path to corresponding output file\n",
    "        out_file = out_path / ref_file.name\n",
    "        \n",
    "        # Check if output file exists\n",
    "        if not out_file.exists():\n",
    "            print(f\"❌ FAIL: Missing output file {out_file}\")\n",
    "            all_match = False\n",
    "            continue\n",
    "        \n",
    "        # Read images\n",
    "        ref_img = cv2.imread(str(ref_file))\n",
    "        out_img = cv2.imread(str(out_file))\n",
    "        \n",
    "        total_images += 1\n",
    "        \n",
    "        # Basic validation\n",
    "        if ref_img is None or out_img is None:\n",
    "            print(f\"❌ FAIL: Could not read images for {ref_file.name}\")\n",
    "            all_match = False\n",
    "            continue\n",
    "            \n",
    "        if ref_img.shape != out_img.shape:\n",
    "            print(f\"❌ FAIL: Image dimensions don't match for {ref_file.name}. \" \n",
    "                  f\"Expected {ref_img.shape}, got {out_img.shape}\")\n",
    "            all_match = False\n",
    "            continue\n",
    "        \n",
    "        # Calculate absolute differences across all channels\n",
    "        diff = np.abs(ref_img.astype(np.float32) - out_img.astype(np.float32))\n",
    "        max_diff = np.max(diff)\n",
    "        mean_diff = np.mean(diff)\n",
    "        \n",
    "        max_differences.append(max_diff)\n",
    "        mean_differences.append(mean_diff)\n",
    "        \n",
    "        # Check if values match within tolerance\n",
    "        image_match = np.all(diff <= tolerance)\n",
    "        \n",
    "        if image_match:\n",
    "            matched_images += 1\n",
    "            if verbose:\n",
    "                print(f\"✅ PASS: {ref_file.name} - Max diff: {max_diff:.4f}, Mean diff: {mean_diff:.4f}\")\n",
    "        else:\n",
    "            all_match = False\n",
    "            print(f\"❌ FAIL: {ref_file.name} - Max diff: {max_diff:.4f}, Mean diff: {mean_diff:.4f}\")\n",
    "            \n",
    "            if verbose:\n",
    "                # Find positions of largest differences\n",
    "                max_pos = np.unravel_index(np.argmax(diff), diff.shape)\n",
    "                print(f\"  - Largest difference at position {max_pos}: {max_diff:.4f}\")\n",
    "                \n",
    "                # Count pixels exceeding tolerance\n",
    "                exceed_count = np.sum(diff > tolerance)\n",
    "                exceed_percent = 100.0 * exceed_count / diff.size\n",
    "                print(f\"  - {exceed_count} pixels ({exceed_percent:.2f}%) exceed tolerance\")\n",
    "    \n",
    "    # Print overall results\n",
    "    if all_match:\n",
    "        print(f\"✅ ALL PASS: All {total_images} images match within tolerance {tolerance}\")\n",
    "    else:\n",
    "        print(f\"⚠️ PARTIAL MATCH: {matched_images}/{total_images} images matched within tolerance {tolerance}\")\n",
    "    \n",
    "    # Print statistics if we had valid comparisons\n",
    "    if max_differences:\n",
    "        print(f\"Overall statistics:\")\n",
    "        print(f\"  - Maximum difference across all images: {max(max_differences):.4f}\")\n",
    "        print(f\"  - Average difference across all images: {np.mean(mean_differences):.4f}\")\n",
    "    \n",
    "    return all_match\n",
    "\n",
    "def verify_batch_processing(kernel_num, reference_folder, output_folder, \n",
    "                            stride=1, batch_size=1, tolerance=20):\n",
    "    \"\"\"\n",
    "    Verify the output of a 3D RGB image convolution kernel against reference images.\n",
    "    \n",
    "    Parameters:\n",
    "    - kernel_num: Kernel number (1, 2, or 3)\n",
    "    - reference_folder: Folder containing reference output images\n",
    "    - output_folder: Folder containing generated output images\n",
    "    - stride: Stride value used for convolution\n",
    "    - batch_size: Batch size used for processing\n",
    "    - tolerance: Maximum allowed difference between corresponding pixel values\n",
    "    \"\"\"\n",
    "    print(f\"\\nVerifying Kernel {kernel_num} output (stride={stride}, batch_size={batch_size}):\")\n",
    "    print(f\"Comparing images in:\")\n",
    "    print(f\"  - Reference: {reference_folder}\")\n",
    "    print(f\"  - Output:    {output_folder}\")\n",
    "    \n",
    "    # Run comparison\n",
    "    start_time = time.time()\n",
    "    result = compare_image_outputs(reference_folder, output_folder, \n",
    "                                  tolerance=tolerance, verbose=True)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Verification completed in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    if result:\n",
    "        print(f\"✅ Kernel {kernel_num} (stride={stride}, batch_size={batch_size}) \"\n",
    "              f\"PASSED verification\")\n",
    "    else:\n",
    "        print(f\"❌ Kernel {kernel_num} (stride={stride}, batch_size={batch_size}) \"\n",
    "              f\"FAILED verification\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "# verify_batch_processing(1, \"reference_images/stride1\", \"output_images/kernel1\", stride=1, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Requriment - 1**\n",
    "- kernel 1 should have no tiling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\n",
      "Compiling kernel 1...\n",
      "e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\cuda_kernels\\stb_image/stb_image.h(4276): warning #550-D: variable \"old_limit\" was set but never used\n",
      "     unsigned int cur, limit, old_limit;\n",
      "                              ^\n",
      "\n",
      "Remark: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
      "\n",
      "e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\cuda_kernels\\stb_image/stb_image.h(5185): warning #550-D: variable \"idata_limit_old\" was set but never used\n",
      "                 stbi__uint32 idata_limit_old = idata_limit;\n",
      "                              ^\n",
      "\n",
      "e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\cuda_kernels\\stb_image/stb_image.h(6972): warning #550-D: variable \"out_size\" was set but never used\n",
      "        int out_size = 0;\n",
      "            ^\n",
      "\n",
      "e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\cuda_kernels\\stb_image/stb_image.h(6973): warning #550-D: variable \"delays_size\" was set but never used\n",
      "        int delays_size = 0;\n",
      "            ^\n",
      "\n",
      "kernel1.cu\n",
      "tmpxft_0000503c_00000000-10_kernel1.cudafe1.cpp\n",
      "   Creating library e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\cuda_kernels\\bin\\kernel1.lib and object e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\cuda_kernels\\bin\\kernel1.exp\n",
      "\n",
      "Running Kernel 1: Basic implementation (no tiling)\n",
      "Batch size: 16\n",
      "Stride: 3\n",
      "Input folder: e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\Input_TestCases\\input_images\n",
      "Output folder: e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\Output_TestCases\\output_images\n",
      "Mask file: e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\Input_TestCases\\masks\\mask9x9_blur.txt\n",
      "Input folder: e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\Input_TestCases\\input_images\n",
      "Output folder: e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\Output_TestCases\\output_images\n",
      "Batch size: 16\n",
      "Mask file: e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\Input_TestCases\\masks\\mask9x9_blur.txt\n",
      "Stride: 3\n",
      "Mask size: 3x3\n",
      "Listing image files in folder: e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\Input_TestCases\\input_images\n",
      "Found 19 image files in total\n",
      "Processing batch of 16 images\n",
      "Processing batch of 3 images\n",
      "Processing complete.\n",
      "\n",
      "Execution completed in 1.1909 seconds\n"
     ]
    }
   ],
   "source": [
    "# Test pair 1: vector=1000, mask=3\n",
    "output = compile_and_run_kernel(1, \"Input_TestCases/input_images\", \"Output_TestCases/output_images\", 16, \"Input_TestCases/masks/mask9x9_blur.txt\",3)\n",
    "# verify_batch_processing(1, \"Output_TestCases/reference_images\", \"Output_TestCases/output_images\", stride=1, batch_size=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Requriment - 2**\n",
    "- kernel 2 should have input tiling \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\n",
      "Compiling kernel 2...\n",
      "e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\cuda_kernels\\stb_image/stb_image.h(4276): warning #550-D: variable \"old_limit\" was set but never used\n",
      "     unsigned int cur, limit, old_limit;\n",
      "                              ^\n",
      "\n",
      "Remark: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
      "\n",
      "e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\cuda_kernels\\stb_image/stb_image.h(5185): warning #550-D: variable \"idata_limit_old\" was set but never used\n",
      "                 stbi__uint32 idata_limit_old = idata_limit;\n",
      "                              ^\n",
      "\n",
      "e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\cuda_kernels\\stb_image/stb_image.h(6972): warning #550-D: variable \"out_size\" was set but never used\n",
      "        int out_size = 0;\n",
      "            ^\n",
      "\n",
      "e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\cuda_kernels\\stb_image/stb_image.h(6973): warning #550-D: variable \"delays_size\" was set but never used\n",
      "        int delays_size = 0;\n",
      "            ^\n",
      "\n",
      "kernel2.cu\n",
      "tmpxft_0000135c_00000000-10_kernel2.cudafe1.cpp\n",
      "   Creating library e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\cuda_kernels\\bin\\kernel2.lib and object e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\cuda_kernels\\bin\\kernel2.exp\n",
      "\n",
      "Running Kernel 2: Tiling with block size matching input tile size\n",
      "Batch size: 16\n",
      "Stride: 3\n",
      "Input folder: e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\Input_TestCases\\input_images\n",
      "Output folder: e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\Output_TestCases\\output_images\n",
      "Mask file: e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\Input_TestCases\\masks\\mask9x9_blur.txt\n",
      "Input folder: e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\Input_TestCases\\input_images\n",
      "Output folder: e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\Output_TestCases\\output_images\n",
      "Batch size: 16\n",
      "Mask file: e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\Input_TestCases\\masks\\mask9x9_blur.txt\n",
      "Stride: 3\n",
      "Mask size: 3x3\n",
      "Listing image files in folder: e:\\02_Learn\\01_University\\Senior-1 Spring\\Current\\Parallel Computing\\Labs\\Lab_5\\Solution\\Input_TestCases\\input_images\n",
      "Found 19 image files in total\n",
      "Processing batch of 16 images\n",
      "Processing batch of 3 images\n",
      "Processing complete.\n",
      "\n",
      "Execution completed in 1.2220 seconds\n"
     ]
    }
   ],
   "source": [
    "# Test pair 2: vector=1000, mask=3\n",
    "output = compile_and_run_kernel(2, \"Input_TestCases/input_images\", \"Output_TestCases/output_images\", 16, \"Input_TestCases/masks/mask9x9_blur.txt\",1)\n",
    "\n",
    "# verify_kernel_output(2, \"conv_v1000_m3\", \"conv_v1000_m3_mask\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Requriment - 3**\n",
    "- kernel 3 should have output tiling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pair 3: vector=1000, mask=3\n",
    "output = compile_and_run_kernel(3, \"Input_TestCases/input_images\", \"Output_TestCases/output_images\", 16, \"Input_TestCases/masks/mask9x9_blur.txt\",2)\n",
    "\n",
    "# verify_kernel_output(3, \"conv_v1000_m3\", \"conv_v1000_m3_mask\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python PyTorch_Implementation.py Input_TestCases/input_images Output_TestCases/reference_images 16 Input_TestCases/masks/mask9x9_blur.txt --stride 3"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
